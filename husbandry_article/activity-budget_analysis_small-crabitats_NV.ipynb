{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c69897ce-391b-4827-85c1-304dab06922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023.\n",
    "# Composed by s.titus@ucl.ac.uk 1 October 2024\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "#################################################################### edit here when graduating from subset to final data \n",
    "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "####################################################################\n",
    "## optional sanity check\n",
    "##df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8a3fc83b-d5bd-4f05-8aa6-45947b9cda9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
    "\n",
    "# Fill any NaNs in the 'human visible?' column with 'N'\n",
    "df['human visible?'] = df['human visible?'].fillna('N')\n",
    "\n",
    "# Function to normalize 'selected observation period start' column\n",
    "def normalize_observation_period_start(df):\n",
    "    def format_time(value):\n",
    "        if isinstance(value, datetime.time):\n",
    "            return value.strftime(\"%H:%M:%S\")\n",
    "        if isinstance(value, str):\n",
    "            return value if len(value) == 8 else value + \":00\"\n",
    "        return value\n",
    "\n",
    "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
    "    return df\n",
    "\n",
    "# Normalize the 'selected observation period start' column\n",
    "df = normalize_observation_period_start(df)\n",
    "\n",
    "# Add a column to store the original row order prior to tide category creation \n",
    "df['original_order'] = df.index\n",
    "\n",
    "# Step 1: Assign Tide Categories and Types\n",
    "def assign_tide_categories_and_types(df):\n",
    "    updated_rows = []  # Placeholder for updated rows\n",
    "\n",
    "    # Group by video file and tide category\n",
    "    grouped = df.groupby(['video file', 'tide category'])\n",
    "\n",
    "    for (video_file, tide_category), group in grouped:\n",
    "        # Check if it's tub data for high/low A and B\n",
    "        if 'tub' in video_file:\n",
    "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
    "            group['tide type'] = tide_type  # Assign tide type\n",
    "            \n",
    "            # Sort by observation period start to rank them properly\n",
    "            group = group.sort_values(by='selected observation period start')\n",
    "\n",
    "            # Rank the observations within each tide category\n",
    "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
    "\n",
    "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
    "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
    "\n",
    "        else:  # For tank data, just assign high or low\n",
    "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
    "            group['tide type'] = tide_type\n",
    "            group['tide category'] = tide_category  # Keep the original category\n",
    "\n",
    "        # Append the updated group to the list\n",
    "        updated_rows.append(group)\n",
    "\n",
    "    # Concatenate all the updated rows into a single DataFrame\n",
    "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
    "\n",
    "    # Drop the extra 'tide category rank' column \n",
    "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "# Apply the function to assign tide categories and types\n",
    "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
    "\n",
    "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
    "def shift_observation_minutes(df):\n",
    "    # Group by video file and tide category\n",
    "    grouped = df.groupby(['video file', 'tide category'])\n",
    "\n",
    "    for (video_file, tide_category), group in grouped:\n",
    "        # If an observation window starts with 0, shift the whole group by +1\n",
    "        if group['observation minute from start'].min() == 0:\n",
    "            df.loc[group.index, 'observation minute from start'] += 1\n",
    "\n",
    "    # Check and remove rows with observation minute 31\n",
    "    df = df[df['observation minute from start'] <= 30]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the observation minute shifting function\n",
    "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
    "\n",
    "# Step 3: Sort by video file, tide category, and observation minute from start\n",
    "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by=['video file', 'tide category', 'observation minute from start'])\n",
    "\n",
    "# Step 4: Reorder Columns to place 'tide type' after 'tide category'\n",
    "columns_order = list(df_with_tide_categories_and_types.columns)\n",
    "columns_order.remove('tide type')\n",
    "tide_category_index = columns_order.index('tide category') + 1\n",
    "columns_order.insert(tide_category_index, 'tide type')\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
    "\n",
    "# Drop the 'original_order' column after sorting\n",
    "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
    "\n",
    "# Save the cleaned DataFrame to Excel\n",
    "file_name, file_extension = os.path.splitext(file_path)\n",
    "output_path_1 = f\"{file_name}_cleaned{file_extension}\" \n",
    "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
    "print(f\"Cleaned dataset saved to: {output_path_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "de8cd4ae-6025-4bc0-9ef6-1e708e3b3ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation issues found:\n",
      "Crab ID: 70 in tub2023-04-23T08_00_00.avi - high A has 12 rows.\n",
      "Crab ID: 66 in tub2023-04-23T08_00_00.avi - high B has 31 rows.\n",
      "Crab ID: 68 in tub2023-04-23T08_00_00.avi - high B has 28 rows.\n",
      "Crab ID: 52 in tub2023-04-23T08_00_00.avi - low A has 9 rows.\n",
      "Crab ID: 58 in tub2023-04-23T08_00_00.avi - low A has 13 rows.\n",
      "Crab ID: 70 in tub2023-04-23T08_00_00.avi - low A has 14 rows.\n",
      "Crab ID: 66 in tub2023-04-23T08_00_00.avi - low B has 8 rows.\n",
      "Crab ID: 70 in tub2023-04-23T08_00_00.avi - low B has 15 rows.\n",
      "Crab ID: 52 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 54 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 57 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 60 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 62 in tub2023-05-24T08_00_00.avi - high B has 3 rows.\n",
      "Crab ID: 66 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 69 in tub2023-05-24T08_00_00.avi - high B has 26 rows.\n",
      "Crab ID: 70 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 71 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 74 in tub2023-05-24T08_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 68 in tub2023-05-24T08_00_00.avi - low A has 46 rows.\n",
      "Crab ID: 1 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 2 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 7 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 16 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 19 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 20 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 21 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 25 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 27 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 30 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 31 in tub2023-07-29T07_00_00.avi - low A has 29 rows.\n",
      "Crab ID: 18 in tub2023-07-29T07_00_00.avi - low B has 2 rows.\n",
      "Crab ID: 28 in tub2023-07-29T07_00_00.avi - low B has 28 rows.\n",
      "Crab ID: 1 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 3 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 4 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 6 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 7 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 23 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 25 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 26 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 27 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 28 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 29 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 30 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 31 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 32 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 34 in tub2023-08-15T11_11_24.avi - high A has 29 rows.\n",
      "Crab ID: 1 in tub2023-08-15T11_11_24.avi - high B has 60 rows.\n",
      "Crab ID: 25 in tub2023-08-15T11_11_24.avi - high B has 36 rows.\n",
      "Crab ID: 33 in tub2023-08-18T07_00_00.avi - high B has 29 rows.\n",
      "Crab ID: 34 in tub2023-08-18T07_00_00.avi - high B has 31 rows.\n",
      "Crab ID: 6 in tub2023-08-19T07_00_00.avi - high A has 29 rows.\n",
      "Crab ID: 27 in tub2023-08-19T07_00_00.avi - high A has 31 rows.\n",
      "Validation summary saved to: C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_cleaned_validation.xlsx\n"
     ]
    }
   ],
   "source": [
    "# DATA VALIDATION (_cleaned) (30obs/crabID)\n",
    "\n",
    "# Check that each crab ID has exactly 30 rows in each observation window\n",
    "def validate_crab_id_rows(df):\n",
    "    # Group by video file, tide category, and crab ID\n",
    "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
    "\n",
    "    # Create a list to hold any validation issues\n",
    "    validation_issues = []\n",
    "\n",
    "    # Iterate through the groups and check row counts\n",
    "    for (video_file, tide_category, crab_id), group in grouped:\n",
    "        count = len(group)\n",
    "        if count != 30:\n",
    "            validation_issues.append({\n",
    "                'video file': video_file,\n",
    "                'tide category': tide_category,\n",
    "                'crab ID': crab_id,\n",
    "                'row count': count\n",
    "            })\n",
    "\n",
    "    return validation_issues\n",
    "\n",
    "# Perform validation\n",
    "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
    "\n",
    "# Output the validation results\n",
    "if validation_results:\n",
    "    print(\"Validation issues found:\")\n",
    "    for issue in validation_results:\n",
    "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
    "else:\n",
    "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
    "\n",
    "# Save validation summary to Excel\n",
    "if validation_results:\n",
    "    # Convert validation issues into a DataFrame\n",
    "    validation_summary_df = pd.DataFrame(validation_results)\n",
    "    \n",
    "    # Specify the path for saving\n",
    "    validation_summary_path = f\"{file_name}_cleaned_validation.xlsx\"\n",
    "    \n",
    "    # Save the DataFrame to Excel\n",
    "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
    "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
    "else:\n",
    "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "01dfcb03-3188-4c0b-9c33-c358f72bbb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataframe including NVs saved to: C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_cleaned+NV.xlsx\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE NV PRESENCE (assign correct sexes, and maintain column/row order with 30 rows per NV crab (i.e., full obs window)) \n",
    "\n",
    "# Function to calculate NV crabs\n",
    "def calculate_nv_crabs_with_sex(df):\n",
    "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
    "\n",
    "    # Group by video file, tide category, and observation period\n",
    "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
    "\n",
    "    for (video_file, tide_category, obs_start), group in grouped:\n",
    "        # Get the present population details\n",
    "        present_population = group['present population'].iloc[0]\n",
    "        present_males = group['present males'].iloc[0]\n",
    "        present_females = group['present females'].iloc[0]\n",
    "        \n",
    "        # Get the observed male and female crab counts (excluding NV crabs)\n",
    "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
    "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
    "        \n",
    "        # Calculate the number of NV males and NV females\n",
    "        num_nv_males = present_males - observed_males\n",
    "        num_nv_females = present_females - observed_females\n",
    "        \n",
    "        # Add NV males with 30 rows each\n",
    "        for i in range(1, num_nv_males + 1):\n",
    "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
    "                nv_male_row = {\n",
    "                    'video file': video_file,\n",
    "                    'crabitat': group['crabitat'].iloc[0],\n",
    "                    'season': group['season'].iloc[0],\n",
    "                    'day type': group['day type'].iloc[0],\n",
    "                    'tide category': tide_category,\n",
    "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
    "                    'present population': present_population,\n",
    "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
    "                    'present males': present_males,\n",
    "                    'present females': present_females,\n",
    "                    'selected observation period start': obs_start,\n",
    "                    'real time': group['real time'].iloc[0],\n",
    "                    'observation minute from start': minute,\n",
    "                    'crab ID': f'NV_m{i}',\n",
    "                    'sex': 'm',  # Assign male\n",
    "                    'instantaneous behaviour': 'NV',\n",
    "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
    "                }\n",
    "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
    "        \n",
    "        # Add NV females with 30 rows each\n",
    "        for i in range(1, num_nv_females + 1):\n",
    "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
    "                nv_female_row = {\n",
    "                    'video file': video_file,\n",
    "                    'crabitat': group['crabitat'].iloc[0],\n",
    "                    'season': group['season'].iloc[0],\n",
    "                    'day type': group['day type'].iloc[0],\n",
    "                    'tide category': tide_category,\n",
    "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
    "                    'present population': present_population,\n",
    "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
    "                    'present males': present_males,\n",
    "                    'present females': present_females,\n",
    "                    'selected observation period start': obs_start,\n",
    "                    'real time': group['real time'].iloc[0],\n",
    "                    'observation minute from start': minute,\n",
    "                    'crab ID': f'NV_f{i}',\n",
    "                    'sex': 'f',  # Assign female\n",
    "                    'instantaneous behaviour': 'NV',\n",
    "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
    "                }\n",
    "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
    "\n",
    "        # Add the original group of observed crabs back to the updated rows\n",
    "        updated_rows.append(group)\n",
    "\n",
    "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
    "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
    "\n",
    "    # Sort the rows based on the original observation order\n",
    "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
    "\n",
    "    # Ensure the correct column order\n",
    "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
    "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
    "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
    "\n",
    "    nv_df = nv_df[column_order]\n",
    "\n",
    "    return nv_df\n",
    "\n",
    "# Apply the NV calculation function\n",
    "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
    "\n",
    "# Remove rows where 'crab ID' is exactly 'NV' - i.e., obs windows where no one showed \n",
    "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
    "\n",
    "# Save the output to a new file\n",
    "output_path_2 = f\"{file_name}_cleaned+NV{file_extension}\"\n",
    "df_with_nv.to_excel(output_path_2, index=False)\n",
    "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "763f0b39-15f9-4b96-930c-b2993b3b296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "Observation minutes out of expected range (1-30).\n",
      "                     video file tide category  expected rows  actual rows  \\\n",
      "0   tank2022-10-04T09_00_00.avi      ebb high             90           30   \n",
      "1   tank2022-10-04T09_00_00.avi       ebb low             90           30   \n",
      "2   tank2022-10-04T09_00_00.avi     flow high             90           30   \n",
      "3   tank2022-10-04T09_00_00.avi      flow low             90           30   \n",
      "4   tank2022-10-21T09_00_00.avi      ebb high            270           30   \n",
      "..                          ...           ...            ...          ...   \n",
      "61   tub2023-08-15T11_11_24.avi           low            690          960   \n",
      "62   tub2023-08-18T07_00_00.avi          high            690         1170   \n",
      "63   tub2023-08-18T07_00_00.avi           low            690         1140   \n",
      "64   tub2023-08-19T07_00_00.avi          high            690         1290   \n",
      "65   tub2023-08-19T07_00_00.avi           low            690         1170   \n",
      "\n",
      "    missing rows  \n",
      "0             60  \n",
      "1             60  \n",
      "2             60  \n",
      "3             60  \n",
      "4            240  \n",
      "..           ...  \n",
      "61          -270  \n",
      "62          -480  \n",
      "63          -450  \n",
      "64          -600  \n",
      "65          -480  \n",
      "\n",
      "[64 rows x 5 columns]\n",
      "Duplicates found:\n",
      "                   video file tide category  \\\n",
      "0  tub2023-04-23T08_00_00.avi          high   \n",
      "1  tub2023-04-23T08_00_00.avi           low   \n",
      "2  tub2023-05-24T08_00_00.avi           low   \n",
      "3  tub2023-08-15T11_11_24.avi          high   \n",
      "4  tub2023-08-18T07_00_00.avi          high   \n",
      "5  tub2023-08-19T07_00_00.avi          high   \n",
      "\n",
      "                                          duplicates  \n",
      "0  [{'video file': 'tub2023-04-23T08_00_00.avi', ...  \n",
      "1  [{'video file': 'tub2023-04-23T08_00_00.avi', ...  \n",
      "2  [{'video file': 'tub2023-05-24T08_00_00.avi', ...  \n",
      "3  [{'video file': 'tub2023-08-15T11_11_24.avi', ...  \n",
      "4  [{'video file': 'tub2023-08-18T07_00_00.avi', ...  \n",
      "5  [{'video file': 'tub2023-08-19T07_00_00.avi', ...  \n",
      "Validation summary saved to: C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_cleaned+NV_validation.xlsx\n",
      "Duplicates saved to: C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_cleaned+NV_duplicates.csv\n"
     ]
    }
   ],
   "source": [
    "# DATA VALIDATION (_cleaned+NV) (30obs/crabID + NV)\n",
    "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
    "\n",
    "def validate_data(df):\n",
    "    # Create a list to store validation results\n",
    "    validation_results = []\n",
    "    # Keep track of duplicates\n",
    "    duplicates_list = []\n",
    "\n",
    "    # Group by video file and tide category\n",
    "    grouped = df.groupby(['video file', 'tide category'])\n",
    "\n",
    "    for (video_file, tide_category), group in grouped:\n",
    "        # Calculate expected number of rows\n",
    "        present_population = group['present population'].iloc[0]\n",
    "        expected_rows = present_population * 30\n",
    "        \n",
    "        # Calculate actual rows based on unique combinations\n",
    "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
    "\n",
    "        missing_rows = expected_rows - actual_rows\n",
    "\n",
    "        # Append validation result to the list\n",
    "        validation_results.append({\n",
    "            'video file': video_file,\n",
    "            'tide category': tide_category,\n",
    "            'expected rows': expected_rows,\n",
    "            'actual rows': actual_rows,\n",
    "            'missing rows': missing_rows\n",
    "        })\n",
    "\n",
    "        # Check for duplicates based on relevant columns\n",
    "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
    "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
    "\n",
    "        # If duplicates exist, append to duplicates list\n",
    "        if not duplicates.empty:\n",
    "            duplicates_list.append({\n",
    "                'video file': video_file,\n",
    "                'tide category': tide_category,\n",
    "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
    "            })\n",
    "\n",
    "        # Check for NaN values in critical columns\n",
    "        for column in ['video file', 'tide category', 'present population']:\n",
    "            if df[column].isnull().any():\n",
    "                print(f\"NaN values found in column '{column}'.\")\n",
    "\n",
    "        # Check observation minute range\n",
    "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
    "            print(\"Observation minutes out of expected range (1-30).\")\n",
    "\n",
    "    # Create a DataFrame from the results list\n",
    "    validation_results_df = pd.DataFrame(validation_results)\n",
    "\n",
    "    # Filter out results with 0 missing rows\n",
    "    validation_results_df = validation_results_df[validation_results_df['missing rows'] != 0]\n",
    "\n",
    "    # Save duplicates if any\n",
    "    duplicates_df = pd.DataFrame(duplicates_list)\n",
    "\n",
    "    # Display the validation summary\n",
    "    print(validation_results_df)\n",
    "    print(\"Duplicates found:\")\n",
    "    print(duplicates_df)\n",
    "\n",
    "    return validation_results_df, duplicates_df\n",
    "\n",
    "# Use the validation function and save outputs\n",
    "validation_summary, duplicates = validate_data(df)\n",
    "\n",
    "# Save validation summary to Excel\n",
    "validation_summary_path = f\"{file_name}_cleaned+NV_validation.xlsx\"\n",
    "validation_summary.to_excel(validation_summary_path, index=False)\n",
    "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
    "\n",
    "# Save duplicates to CSV if needed\n",
    "if not duplicates.empty:\n",
    "    duplicates_path = f\"{file_name}_cleaned+NV_duplicates.csv\"\n",
    "    duplicates.to_csv(duplicates_path, index=False)\n",
    "    print(f\"Duplicates saved to: {duplicates_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fcf426e8-ee1b-459a-8d0d-caea6199d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "filepath = C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET\n",
      "import pandas as pd\n",
      "filepath = C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET\n",
      "import pandas as pd\n",
      "filepath = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "# Function to assign unique tide identifiers for the tub\n",
      "def assign_tide_identifiers(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            # Get the time of the observations\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                if tide_category == 'high':\n",
      "                    tide_label = f'high {tide_ids[idx]}'\n",
      "                elif tide_category == 'low':\n",
      "                    tide_label = f'low {tide_ids[idx]}'\n",
      "                else:\n",
      "                    tide_label = tide_category  # Keep existing label for tank\n",
      "\n",
      "                # Update the rows with the new tide label\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_label  # Assign the new tide label\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_rows.append(row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers(df)\n",
      "\n",
      "# Display the updated DataFrame with new tide identifiers\n",
      "df_with_tide_ids.head()\n",
      "# Function to assign unique tide identifiers for the tub\n",
      "def assign_tide_identifiers(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            # Get the time of the observations\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                if tide_category == 'high':\n",
      "                    tide_label = f'high {tide_ids[idx]}'\n",
      "                elif tide_category == 'low':\n",
      "                    tide_label = f'low {tide_ids[idx]}'\n",
      "                else:\n",
      "                    tide_label = tide_category  # Keep existing label for tank\n",
      "\n",
      "                # Update the rows with the new tide label\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_label  # Assign the new tide label\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_rows.append(row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_ids[df_with_tide_ids['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide identifiers\n",
      "import pandas as pd\n",
      "\n",
      "# Load the Excel file (adjust the path accordingly)\n",
      "file_path = 'path_to_your_file_here.xlsx'  # Replace with the actual file path\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "\n",
      "# Function to assign unique tide identifiers for the tub and standardize observation times\n",
      "def assign_tide_identifiers_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories and standardize time\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                tide_label = f'{tide_category} {tide_ids[idx]}'\n",
      "                \n",
      "                # Update the rows with the new tide label and standardized time\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide identifier'] = tide_label  # Assign a new column for the tide identifier\n",
      "                    updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                    # Standardize the time\n",
      "                    if updated_row['minute'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['minute'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide identifier'] = tide_category  # Maintain the existing category\n",
      "                updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['minute'] == 0:\n",
      "                    updated_row['minute'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_ids[df_with_tide_ids['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide identifiers\n",
      "# Function to assign unique tide identifiers for the tub and standardize observation times\n",
      "def assign_tide_identifiers_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories and standardize time\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                tide_label = f'{tide_category} {tide_ids[idx]}'\n",
      "                \n",
      "                # Update the rows with the new tide label and standardized time\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide identifier'] = tide_label  # Assign a new column for the tide identifier\n",
      "                    updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                    # Standardize the time\n",
      "                    if updated_row['minute'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['minute'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide identifier'] = tide_category  # Maintain the existing category\n",
      "                updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['minute'] == 0:\n",
      "                    updated_row['minute'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_ids[df_with_tide_ids['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide identifiers\n",
      "# Function to assign unique tide identifiers for the tub and standardize observation times\n",
      "def assign_tide_identifiers_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories and standardize time\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                tide_label = f'{tide_category} {tide_ids[idx]}'\n",
      "                \n",
      "                # Update the rows with the new tide label and standardized time\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide identifier'] = tide_label  # Assign a new column for the tide identifier\n",
      "                    updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                    # Standardize the time\n",
      "                    if updated_row['minute'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['minute'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide identifier'] = tide_category  # Maintain the existing category\n",
      "                updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_ids[df_with_tide_ids['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide identifiers\n",
      "# Function to assign unique tide identifiers for the tub and standardize observation times\n",
      "def assign_tide_identifiers_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories and standardize time\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                tide_label = f'{tide_category} {tide_ids[idx]}'\n",
      "                \n",
      "                # Update the rows with the new tide label and standardized time\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide identifier'] = tide_label  # Assign a new column for the tide identifier\n",
      "                    updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide identifier'] = tide_category  # Maintain the existing category\n",
      "                updated_row['tide type'] = tide_category  # Add combined overview column\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_ids[df_with_tide_ids['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide identifiers\n",
      "# Function to assign tide types and standardize observation times\n",
      "def assign_tide_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and standardize time\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                tide_type = f'{tide_category} {tide_ids[idx]}'\n",
      "                \n",
      "                # Update the rows with the new tide type and standardized time\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide type'] = tide_type  # Assign a new column for the tide type\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide type'] = tide_category  # Maintain the existing category\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_types = assign_tide_types_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_types[df_with_tide_types['video file'].str.contains('tub')]\n",
      "tub_data.head(50)  # Show the first ten rows of tub data to inspect tide types and timing\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Assign high A/B or low A/B based on the tide category\n",
      "            tide_ids = {0: 'high A', 1: 'high B', 2: 'low A', 3: 'low B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                tide_category_name = tide_ids[idx]  # Get tide category name\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide categories and types\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Assign high A/B or low A/B based on the tide category\n",
      "            tide_ids = {0: 'high A', 1: 'high B', 2: 'low A', 3: 'low B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                tide_category_name = tide_ids[idx]  # Get tide category name\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "tub_data.head(50)  # Show the first ten rows of tub data to inspect tide categories and types\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Assign high A/B or low A/B based on the tide category\n",
      "            tide_ids = {0: 'high A', 1: 'high B', 2: 'low A', 3: 'low B'}\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                tide_category_name = tide_ids[idx]  # Get tide category name\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "tub_data.head(100)  # Show the first ten rows of tub data to inspect tide categories and types\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Use a counter to differentiate high A and high B\n",
      "            high_count = 0\n",
      "            low_count = 0\n",
      "            \n",
      "            for minute, time_group in group.groupby('selected observation period start'):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Increment counters based on tide type\n",
      "                if tide_type == 'high':\n",
      "                    tide_category_name = f'high {chr(65 + high_count)}'  # A, B, etc.\n",
      "                    high_count += 1\n",
      "                else:\n",
      "                    tide_category_name = f'low {chr(65 + low_count)}'  # A, B, etc.\n",
      "                    low_count += 1\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first few rows of the updated DataFrame\n",
      "print(df_with_tide_categories_and_types.head())\n",
      "# Function to assign unique tide identifiers for the tub\n",
      "def assign_tide_identifiers(df):\n",
      "    updated_rows = []  # Placeholder for rows with NV crabs to be added\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign identifiers for tub tide categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            tide_ids = {0: 'A', 1: 'B'}\n",
      "            # Get the time of the observations\n",
      "            for idx, (minute, time_group) in enumerate(group.groupby('selected observation period start')):\n",
      "                # Assign high A/B or low A/B based on the tide category\n",
      "                if tide_category == 'high':\n",
      "                    tide_label = f'high {tide_ids[idx]}'\n",
      "                elif tide_category == 'low':\n",
      "                    tide_label = f'low {tide_ids[idx]}'\n",
      "                else:\n",
      "                    tide_label = tide_category  # Keep existing label for tank\n",
      "\n",
      "                # Update the rows with the new tide label\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_label  # Assign the new tide label\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, simply append without changing tide category\n",
      "            for _, row in group.iterrows():\n",
      "                updated_rows.append(row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_ids = assign_tide_identifiers(df)\n",
      "\n",
      "# Display the updated DataFrame filtered for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "tub_data.head(10)  # Show the first ten rows of tub data to inspect tide categories and types\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "tub_data.head(100)  # Show the first ten rows of tub data to inspect tide categories and types\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Use counters to differentiate high A and high B\n",
      "            high_count = 0\n",
      "            low_count = 0\n",
      "            \n",
      "            for minute, time_group in group.groupby('selected observation period start'):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Increment counters based on tide type\n",
      "                if tide_type == 'high':\n",
      "                    tide_category_name = f'high {chr(65 + high_count)}'  # A, B, etc.\n",
      "                    high_count += 1\n",
      "                else:\n",
      "                    tide_category_name = f'low {chr(65 + low_count)}'  # A, B, etc.\n",
      "                    low_count += 1\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first few rows of the updated DataFrame\n",
      "print(df_with_tide_categories_and_types.head())\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "tub_data.head(100)  # Show the first ten rows of tub data to inspect tide categories and types\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Use counters to differentiate high A and high B\n",
      "            high_count = 0\n",
      "            low_count = 0\n",
      "            \n",
      "            for minute, time_group in group.groupby('selected observation period start'):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Increment counters based on tide type\n",
      "                if tide_type == 'high':\n",
      "                    tide_category_name = f'high {chr(65 + high_count)}'  # A, B, etc.\n",
      "                    high_count += 1\n",
      "                else:\n",
      "                    tide_category_name = f'low {chr(65 + low_count)}'  # A, B, etc.\n",
      "                    low_count += 1\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first few rows of the updated DataFrame\n",
      "print(df_with_tide_categories_and_types.head())\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Use counters to differentiate high A and high B\n",
      "            high_count = 0\n",
      "            low_count = 0\n",
      "            \n",
      "            for minute, time_group in group.groupby('selected observation period start'):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Increment counters based on tide type\n",
      "                if tide_type == 'high':\n",
      "                    tide_category_name = f'high {chr(65 + high_count)}'  # A, B, etc.\n",
      "                    high_count += 1\n",
      "                else:\n",
      "                    tide_category_name = f'low {chr(65 + low_count)}'  # A, B, etc.\n",
      "                    low_count += 1\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "print(tank_data.head(100))\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Use counters to differentiate high A and high B\n",
      "            high_count = 0\n",
      "            low_count = 0\n",
      "            \n",
      "            for minute, time_group in group.groupby('selected observation period start'):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category (high A or high B)\n",
      "                if tide_type == 'high':\n",
      "                    tide_category_name = f'high {chr(65 + high_count)}'  # A, B, etc.\n",
      "                    high_count += 1\n",
      "                else:\n",
      "                    tide_category_name = f'low {chr(65 + low_count)}'  # A, B, etc.\n",
      "                    low_count += 1\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "print(tank_data.head(100))\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            # Use counters to differentiate high A and high B\n",
      "            high_count = 0\n",
      "            low_count = 0\n",
      "            \n",
      "            for minute, time_group in group.groupby('selected observation period start'):\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category (high A or high B)\n",
      "                if 'high' in tide_category:\n",
      "                    tide_category_name = f'high {chr(65 + high_count)}'  # A, B, etc.\n",
      "                    high_count += 1\n",
      "                elif 'low' in tide_category:\n",
      "                    tide_category_name = f'low {chr(65 + low_count)}'  # A, B, etc.\n",
      "                    low_count += 1\n",
      "\n",
      "                # Update the rows with the new tide type and category\n",
      "                for i in range(len(time_group)):\n",
      "                    updated_row = time_group.iloc[i].copy()\n",
      "                    updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                    updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                    # Standardize the time\n",
      "                    if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                        updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                    updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "print(tank_data.head(100))\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            high_count = 0  # Count of high tides (A, B)\n",
      "            low_count = 0   # Count of low tides (A, B)\n",
      "\n",
      "            # Iterate over each row to assign tide category based on the sequence\n",
      "            for index, row in group.iterrows():\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category name\n",
      "                if 'high' in tide_category:\n",
      "                    if high_count == 0:\n",
      "                        tide_category_name = 'high A'\n",
      "                    else:\n",
      "                        tide_category_name = 'high B'\n",
      "                    high_count += 1  # Increment high tide count\n",
      "                elif 'low' in tide_category:\n",
      "                    if low_count == 0:\n",
      "                        tide_category_name = 'low A'\n",
      "                    else:\n",
      "                        tide_category_name = 'low B'\n",
      "                    low_count += 1  # Increment low tide count\n",
      "                \n",
      "                # Update the row with the new tide category and type\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                \n",
      "                # Standardize the time\n",
      "                if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                \n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "# Display the first 100 rows for tub data\n",
      "tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "print(tank_data.head(100))\n",
      "def create_nv_datasets(df):\n",
      "    # Create a DataFrame with NVs included\n",
      "    nv_df = df.copy()\n",
      "\n",
      "    # Identify crabs that are not visible (NV)\n",
      "    nv_rows = []  # List to hold NV rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = nv_df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        observed_crabs = group['crab ID'].nunique()\n",
      "        missing_crabs = present_population - observed_crabs\n",
      "\n",
      "        # If there are missing crabs, create NV entries\n",
      "        if missing_crabs > 0:\n",
      "            # Create NV entries\n",
      "            for _ in range(missing_crabs):\n",
      "                # Create a new NV entry\n",
      "                nv_entry = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': 'NV',\n",
      "                    'observation minute from start': list(range(1, 31)),  # 1-30 minutes\n",
      "                    'crab ID': f'NV_{video_file}_{_ + 1}',  # Unique NV ID\n",
      "                    'human visible?': 'N',  # Assuming not visible\n",
      "                    # Add other relevant columns with NaN or default values\n",
      "                }\n",
      "                nv_rows.extend([nv_entry] * 30)  # 30 rows for each NV crab\n",
      "                \n",
      "    # Combine NV entries with original DataFrame\n",
      "    nv_df = pd.concat([nv_df, pd.DataFrame(nv_rows)], ignore_index=True)\n",
      "\n",
      "    # Create a DataFrame without NVs\n",
      "    without_nv_df = df[~df['crab ID'].astype(str).str.contains('NV')]\n",
      "\n",
      "    # Optionally: Drop rows where all crabs are NV for certain conditions\n",
      "    # Example: Drop rows where 'human visible?' is NaN and present population is 0\n",
      "    without_nv_df = without_nv_df[~(without_nv_df['human visible?'].isna() & (without_nv_df['present population'] == 0))]\n",
      "\n",
      "    # Save to Excel files\n",
      "    nv_df.to_excel('path_to_your_file/nv_dataset.xlsx', index=False)\n",
      "    without_nv_df.to_excel('path_to_your_file/without_nv_dataset.xlsx', index=False)\n",
      "\n",
      "    return nv_df, without_nv_df\n",
      "\n",
      "# Create datasets\n",
      "nv_dataset, without_nv_dataset = create_nv_datasets(df)\n",
      "\n",
      "# Display the first few rows of each dataset\n",
      "print(\"NV Dataset:\")\n",
      "print(nv_dataset.head())\n",
      "\n",
      "print(\"\\nWithout NV Dataset:\")\n",
      "print(without_nv_dataset.head())\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            high_count = 0  # Count of high tides (A, B)\n",
      "            low_count = 0   # Count of low tides (A, B)\n",
      "\n",
      "            # Iterate over each row to assign tide category based on the sequence\n",
      "            for index, row in group.iterrows():\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category name\n",
      "                if 'high' in tide_category:\n",
      "                    if high_count == 0:\n",
      "                        tide_category_name = 'high A'\n",
      "                    else:\n",
      "                        tide_category_name = 'high B'\n",
      "                    high_count += 1  # Increment high tide count\n",
      "                elif 'low' in tide_category:\n",
      "                    if low_count == 0:\n",
      "                        tide_category_name = 'low A'\n",
      "                    else:\n",
      "                        tide_category_name = 'low B'\n",
      "                    low_count += 1  # Increment low tide count\n",
      "                \n",
      "                # Update the row with the new tide category and type\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                \n",
      "                # Standardize the time\n",
      "                if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                \n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "def create_nv_datasets(df):\n",
      "    # Create a DataFrame with NVs included\n",
      "    nv_df = df.copy()\n",
      "\n",
      "    # Identify crabs that are not visible (NV)\n",
      "    nv_rows = []  # List to hold NV rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = nv_df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        observed_crabs = group['crab ID'].nunique()\n",
      "        missing_crabs = present_population - observed_crabs\n",
      "\n",
      "        # If there are missing crabs, create NV entries\n",
      "        if missing_crabs > 0:\n",
      "            # Create NV entries\n",
      "            for _ in range(missing_crabs):\n",
      "                # Create a new NV entry\n",
      "                nv_entry = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': 'NV',\n",
      "                    'observation minute from start': list(range(1, 31)),  # 1-30 minutes\n",
      "                    'crab ID': f'NV_{video_file}_{_ + 1}',  # Unique NV ID\n",
      "                    'human visible?': 'N',  # Assuming not visible\n",
      "                    # Add other relevant columns with NaN or default values\n",
      "                }\n",
      "                nv_rows.extend([nv_entry] * 30)  # 30 rows for each NV crab\n",
      "                \n",
      "    # Combine NV entries with original DataFrame\n",
      "    nv_df = pd.concat([nv_df, pd.DataFrame(nv_rows)], ignore_index=True)\n",
      "\n",
      "    # Create a DataFrame without NVs\n",
      "    without_nv_df = df[~df['crab ID'].astype(str).str.contains('NV')]\n",
      "\n",
      "    # Optionally: Drop rows where all crabs are NV for certain conditions\n",
      "    # Example: Drop rows where 'human visible?' is NaN and present population is 0\n",
      "    without_nv_df = without_nv_df[~(without_nv_df['human visible?'].isna() & (without_nv_df['present population'] == 0))]\n",
      "\n",
      "    # Save to Excel files\n",
      "    nv_df.to_excel('path_to_your_file/nv_dataset.xlsx', index=False)\n",
      "    without_nv_df.to_excel('path_to_your_file/without_nv_dataset.xlsx', index=False)\n",
      "\n",
      "    return nv_df, without_nv_df\n",
      "\n",
      "# Create datasets\n",
      "nv_dataset, without_nv_dataset = create_nv_datasets(df)\n",
      "\n",
      "# Display the first few rows of each dataset\n",
      "print(\"NV Dataset:\")\n",
      "print(nv_dataset.head())\n",
      "\n",
      "print(\"\\nWithout NV Dataset:\")\n",
      "print(without_nv_dataset.head())\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            high_count = 0  # Count of high tides (A, B)\n",
      "            low_count = 0   # Count of low tides (A, B)\n",
      "\n",
      "            # Iterate over each row to assign tide category based on the sequence\n",
      "            for index, row in group.iterrows():\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category name\n",
      "                if 'high' in tide_category:\n",
      "                    if high_count == 0:\n",
      "                        tide_category_name = 'high A'\n",
      "                    else:\n",
      "                        tide_category_name = 'high B'\n",
      "                    high_count += 1  # Increment high tide count\n",
      "                elif 'low' in tide_category:\n",
      "                    if low_count == 0:\n",
      "                        tide_category_name = 'low A'\n",
      "                    else:\n",
      "                        tide_category_name = 'low B'\n",
      "                    low_count += 1  # Increment low tide count\n",
      "                \n",
      "                # Update the row with the new tide category and type\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                \n",
      "                # Standardize the time\n",
      "                if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                \n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "###### PREVIOUS gpt response from Monday afternoon - def create_nv_datasets(df):\n",
      "    # Create a DataFrame with NVs included\n",
      "    nv_df = df.copy()\n",
      "\n",
      "    # Identify crabs that are not visible (NV)\n",
      "    nv_rows = []  # List to hold NV rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = nv_df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        observed_crabs = group['crab ID'].nunique()\n",
      "        missing_crabs = present_population - observed_crabs\n",
      "\n",
      "        # If there are missing crabs, create NV entries\n",
      "        if missing_crabs > 0:\n",
      "            # Create NV entries\n",
      "            for _ in range(missing_crabs):\n",
      "                # Create a new NV entry\n",
      "                nv_entry = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': 'NV',\n",
      "                    'observation minute from start': list(range(1, 31)),  # 1-30 minutes\n",
      "                    'crab ID': f'NV_{video_file}_{_ + 1}',  # Unique NV ID\n",
      "                    'human visible?': 'N',  # Assuming not visible\n",
      "                    # Add other relevant columns with NaN or default values\n",
      "                }\n",
      "                nv_rows.extend([nv_entry] * 30)  # 30 rows for each NV crab\n",
      "                \n",
      "    # Combine NV entries with original DataFrame\n",
      "    nv_df = pd.concat([nv_df, pd.DataFrame(nv_rows)], ignore_index=True)\n",
      "\n",
      "    # Create a DataFrame without NVs\n",
      "    without_nv_df = df[~df['crab ID'].astype(str).str.contains('NV')]\n",
      "\n",
      "    # Optionally: Drop rows where all crabs are NV for certain conditions\n",
      "    # Example: Drop rows where 'human visible?' is NaN and present population is 0\n",
      "    without_nv_df = without_nv_df[~(without_nv_df['human visible?'].isna() & (without_nv_df['present population'] == 0))]\n",
      "\n",
      "    # Save to Excel files\n",
      "    nv_df.to_excel('path_to_your_file/nv_dataset.xlsx', index=False)\n",
      "    without_nv_df.to_excel('path_to_your_file/without_nv_dataset.xlsx', index=False)\n",
      "\n",
      "    return nv_df, without_nv_df\n",
      "\n",
      "# Create datasets\n",
      "nv_dataset, without_nv_dataset = create_nv_datasets(df)\n",
      "\n",
      "# Display the first few rows of each dataset\n",
      "print(\"NV Dataset:\")\n",
      "print(nv_dataset.head())\n",
      "\n",
      "print(\"\\nWithout NV Dataset:\")\n",
      "print(without_nv_dataset.head())\n",
      "###### RECENT gpt response from Monday afternoon -\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            high_count = 0  # Count of high tides (A, B)\n",
      "            low_count = 0   # Count of low tides (A, B)\n",
      "\n",
      "            # Iterate over each row to assign tide category based on the sequence\n",
      "            for index, row in group.iterrows():\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category name\n",
      "                if 'high' in tide_category:\n",
      "                    if high_count == 0:\n",
      "                        tide_category_name = 'high A'\n",
      "                    else:\n",
      "                        tide_category_name = 'high B'\n",
      "                    high_count += 1  # Increment high tide count\n",
      "                elif 'low' in tide_category:\n",
      "                    if low_count == 0:\n",
      "                        tide_category_name = 'low A'\n",
      "                    else:\n",
      "                        tide_category_name = 'low B'\n",
      "                    low_count += 1  # Increment low tide count\n",
      "                \n",
      "                # Update the row with the new tide category and type\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                \n",
      "                # Standardize the time\n",
      "                if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                \n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "# Function to assign tide categories and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Get the present population and unique observed crabs in this video file + tide category\n",
      "        present_population = group['present population'].iloc[0]  # Total population in this tide category\n",
      "        observed_crabs = group['crab ID'].nunique()  # Number of unique crabs observed\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories\n",
      "        if 'tub' in video_file:  # Check if it's tub data\n",
      "            high_count = 0  # Count of high tides (A, B)\n",
      "            low_count = 0   # Count of low tides (A, B)\n",
      "\n",
      "            # Iterate over each row to assign tide category based on the sequence\n",
      "            for index, row in group.iterrows():\n",
      "                tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "                \n",
      "                # Determine tide category name\n",
      "                if 'high' in tide_category:\n",
      "                    if high_count == 0:\n",
      "                        tide_category_name = 'high A'\n",
      "                    else:\n",
      "                        tide_category_name = 'high B'\n",
      "                    high_count += 1  # Increment high tide count\n",
      "                elif 'low' in tide_category:\n",
      "                    if low_count == 0:\n",
      "                        tide_category_name = 'low A'\n",
      "                    else:\n",
      "                        tide_category_name = 'low B'\n",
      "                    low_count += 1  # Increment low tide count\n",
      "                \n",
      "                # Update the row with the new tide category and type\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category_name  # Assign new tide category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                \n",
      "                # Standardize the time\n",
      "                if updated_row['observation minute from start'] == 0:  # Shift all 0-29 to 1-30\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                \n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data, assign general tide type\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time if it starts at minute 0\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1  # Set minute to 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file, tide category, and start time\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, start_time), group in grouped:\n",
      "        # Get the present population and unique observed crabs\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        observed_crabs = group['crab ID'].nunique()\n",
      "        missing_crabs = present_population - observed_crabs  # Crabs not visible (NV)\n",
      "\n",
      "        # Assign tide types and categories for tub data\n",
      "        if 'tub' in video_file:\n",
      "            # Determine if it is high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "\n",
      "            # Create flags for A and B assignment based on the combination of file, tide, and start time\n",
      "            tide_category_name = f\"{tide_type} A\" if start_time == group['selected observation period start'].min() else f\"{tide_type} B\"\n",
      "\n",
      "            # Update all rows in this group with the correct tide category and type\n",
      "            for index, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category_name  # Assign new tide category (A/B)\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time (shift 0-29 to 1-30)\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "        else:  # For tank data\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            for _, row in group.iterrows():\n",
      "                updated_row = row.copy()\n",
      "                updated_row['tide category'] = tide_category  # Keep existing tide category\n",
      "                updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "                # Standardize the time (shift 0-29 to 1-30)\n",
      "                if updated_row['observation minute from start'] == 0:\n",
      "                    updated_row['observation minute from start'] = 1\n",
      "                updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the list of new rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "    \n",
      "    # Sort by video file and observation minute to preserve order\n",
      "    updated_df.sort_values(by=['video file', 'selected observation period start', 'observation minute from start'], inplace=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Save the modified dataset\n",
      "df_with_tide_categories_and_types.to_excel(\"updated_data_with_tides.xlsx\", index=False)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file, tide category, and observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "\n",
      "            # Assign A for the first occurrence and B for the second within the same file + tide category + start time\n",
      "            count_A_B = group['selected observation period start'].rank(method='dense').astype(int)\n",
      "            group['tide category'] = group['tide category'] + \" \" + count_A_B.map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:\n",
      "            # For tank data, no A/B assignment, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "\n",
      "        # Standardize the observation minute from start (0-29 to 1-30)\n",
      "        group['observation minute from start'] = group['observation minute from start'].replace(0, 1)\n",
      "\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file, tide category, and observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "\n",
      "            # Assign A for the first occurrence and B for the second within the same file + tide category + start time\n",
      "            count_A_B = group['selected observation period start'].rank(method='dense').astype(int)\n",
      "            group['tide category'] = group['tide category'] + \" \" + count_A_B.map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:\n",
      "            # For tank data, no A/B assignment, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "\n",
      "        # Standardize the observation minute from start (0-29 to 1-30)\n",
      "        group['observation minute from start'] = group['observation minute from start'].replace(0, 1)\n",
      "\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "# Function to standardize observation minutes and correctly assign A/B for tide categories\n",
      "def process_tide_categories_and_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minutes (shift all 0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file, tide category, and observation start time\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for i, (group_key, group) in enumerate(grouped):\n",
      "        # Unpack group_key for clarity\n",
      "        video_file, tide_category, start_time = group_key\n",
      "        \n",
      "        # Determine the tide type (high or low)\n",
      "        if 'high' in tide_category:\n",
      "            tide_type = 'high'\n",
      "        else:\n",
      "            tide_type = 'low'\n",
      "\n",
      "        # Alternate between A and B for the first and second occurrence of each unique combination\n",
      "        tide_category_label = 'A' if i % 2 == 0 else 'B'\n",
      "\n",
      "        # Update each row in the group\n",
      "        for _, row in group.iterrows():\n",
      "            updated_row = row.copy()\n",
      "            updated_row['tide category'] = f\"{tide_type} {tide_category_label}\"  # e.g., \"high A\", \"low B\"\n",
      "            updated_row['tide type'] = tide_type  # Either 'high' or 'low'\n",
      "\n",
      "            updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the updated rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_processed = process_tide_categories_and_time(df)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "# Function to standardize observation minutes and correctly assign A/B for tide categories\n",
      "def process_tide_categories_and_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minutes (shift all 0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file, tide category, and observation start time\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for i, (group_key, group) in enumerate(grouped):\n",
      "        # Unpack group_key for clarity\n",
      "        video_file, tide_category, start_time = group_key\n",
      "        \n",
      "        # Determine tide type (high or low)\n",
      "        tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "\n",
      "        # Assign A/B labels based on occurrence in the group\n",
      "        tide_category_label = 'A' if i % 2 == 0 else 'B'\n",
      "\n",
      "        # Update each row in the group\n",
      "        for _, row in group.iterrows():\n",
      "            updated_row = row.copy()\n",
      "            updated_row['tide category'] = f\"{tide_type} {tide_category_label}\"  # e.g., \"high A\", \"low B\"\n",
      "            updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "\n",
      "            updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the updated rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_processed = process_tide_categories_and_time(df)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "updated_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(updated_file_path, index=False)\n",
      "# Function to standardize observation minutes and correctly assign A/B for tide categories\n",
      "def process_tide_categories_and_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minutes (shift all 0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Create a new column to distinguish tide identifiers\n",
      "    df['tide identifier'] = ''\n",
      "\n",
      "    # Group by video file, tide category, and observation start time\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    # Iterate through each group to assign A/B labels and tide type\n",
      "    for group_key, group in grouped:\n",
      "        video_file, tide_category, start_time = group_key\n",
      "        \n",
      "        # Determine tide type (high or low)\n",
      "        tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "\n",
      "        # Count occurrences to determine A/B labels\n",
      "        unique_identifier = f\"{video_file}_{tide_category}_{start_time}\"\n",
      "        \n",
      "        # Assign A or B based on the occurrence of the unique identifier\n",
      "        if unique_identifier not in df['tide identifier'].values:\n",
      "            tide_category_label = 'A'\n",
      "        else:\n",
      "            tide_category_label = 'B'\n",
      "\n",
      "        # Update each row in the group\n",
      "        for index, row in group.iterrows():\n",
      "            updated_row = row.copy()\n",
      "            updated_row['tide category'] = f\"{tide_type} {tide_category_label}\"  # e.g., \"high A\", \"low B\"\n",
      "            updated_row['tide type'] = tide_type  # Assign tide type (high or low)\n",
      "\n",
      "            # Update the tide identifier column\n",
      "            updated_row['tide identifier'] = unique_identifier\n",
      "\n",
      "            updated_rows.append(updated_row)\n",
      "\n",
      "    # Convert the updated rows into a DataFrame\n",
      "    updated_df = pd.DataFrame(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_processed = process_tide_categories_and_time(df)\n",
      "\n",
      "# Display the first 100 rows for tub data\n",
      "#tub_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tub')]\n",
      "#print(tub_data.head(100))\n",
      "\n",
      "# Display the first 100 rows for tank data\n",
      "#tank_data = df_with_tide_categories_and_types[df_with_tide_categories_and_types['video file'].str.contains('tank')]\n",
      "#print(tank_data.head(100))\n",
      "\n",
      "# Save updated DataFrame to Excel\n",
      "output_file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_processed.to_excel(output_file_path, index=False)\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file, tide category, and observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "\n",
      "            # Assign A for the first occurrence and B for the second within the same file + tide category + start time\n",
      "            count_A_B = group['selected observation period start'].rank(method='dense').astype(int)\n",
      "            group['tide category'] = group['tide category'] + \" \" + count_A_B.map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:\n",
      "            # For tank data, no A/B assignment, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "\n",
      "        # Standardize the observation minute from start (0-29 to 1-30)\n",
      "        group['observation minute from start'] = group['observation minute from start'].replace(0, 1)\n",
      "\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Display the first few rows to check the changes\n",
      "#print(df_with_tide_categories_and_types.head(100))\n",
      "\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types_and_standardize_time(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file, tide category, and selected observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Create a unique identifier for each combination\n",
      "            unique_identifier = f\"{video_file}_{tide_category}_{obs_start}\"\n",
      "            # Rank unique combinations to assign A or B\n",
      "            tide_category_label = group['selected observation period start'].rank(method='dense').astype(int)\n",
      "            group['tide category'] = tide_category + \" \" + tide_category_label.map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to the DataFrame\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types_and_standardize_time(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to separate sex ratio into male and female counts\n",
      "def separate_sex_ratio(df):\n",
      "    df[['present males', 'present females']] = df['present sex ratio'].str.split(';', expand=True)\n",
      "    # Convert the new columns to numeric for easier analysis\n",
      "    df['present males'] = pd.to_numeric(df['present males'], errors='coerce')\n",
      "    df['present females'] = pd.to_numeric(df['present females'], errors='coerce')\n",
      "    return df\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file, tide category, and selected observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Create a unique identifier for each combination\n",
      "            unique_identifier = f\"{video_file}_{tide_category}_{obs_start}\"\n",
      "            # Assign A or B based on the order of the observation window (1st gets A, 2nd gets B)\n",
      "            tide_rank = group['selected observation period start'].rank(method='dense').astype(int)\n",
      "            group['tide category'] = tide_category + \" \" + tide_rank.map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file, tide category, and selected observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    # Initialize a dictionary to keep track of counts for each unique tide category within a tub\n",
      "    tide_counts = {}\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Create a unique identifier for each combination\n",
      "            unique_identifier = f\"{video_file}_{tide_category}_{obs_start}\"\n",
      "\n",
      "            # Initialize the counter for this tide category if not already done\n",
      "            if unique_identifier not in tide_counts:\n",
      "                tide_counts[unique_identifier] = 0\n",
      "            \n",
      "            # Increment the counter for this tide category\n",
      "            tide_counts[unique_identifier] += 1\n",
      "\n",
      "            # Assign A to the first occurrence and B to the second for each unique identifier\n",
      "            tide_category_label = 'A' if tide_counts[unique_identifier] == 1 else 'B'\n",
      "            group['tide category'] = tide_category + \" \" + tide_category_label\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Initialize a dictionary to track unique combinations for tub data\n",
      "    tide_tracker = {}\n",
      "\n",
      "    # Group by video file, tide category, and selected observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Create a unique identifier for the tide category\n",
      "            key = f\"{video_file}_{tide_category}_{obs_start}\"\n",
      "            \n",
      "            # Check if this tide category has been seen before\n",
      "            if key not in tide_tracker:\n",
      "                tide_tracker[key] = 0\n",
      "            \n",
      "            # Increment the count for this tide category\n",
      "            tide_tracker[key] += 1\n",
      "            \n",
      "            # Assign A to the first occurrence and B to the second for each tide type\n",
      "            if tide_tracker[key] == 1:\n",
      "                group['tide category'] = tide_category + \" A\"\n",
      "            elif tide_tracker[key] == 2:\n",
      "                group['tide category'] = tide_category + \" B\"\n",
      "                \n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file, tide category, and selected observation period start\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "# Function to handle the datetime conversion for 'selected observation period start'\n",
      "def standardize_observation_period_start(df):\n",
      "    # Attempt to convert the 'selected observation period start' column to datetime\n",
      "    try:\n",
      "        df['selected observation period start'] = pd.to_datetime(df['selected observation period start'], errors='coerce').dt.time\n",
      "    except Exception as e:\n",
      "        print(f\"Error converting 'selected observation period start': {e}\")\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category (we'll handle sorting by time in the next step)\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Assign A or B based on the rank of each observation period\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Standardize the observation period start\n",
      "df = standardize_observation_period_start(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "# Function to handle the datetime conversion for 'selected observation period start'\n",
      "def standardize_observation_period_start(df):\n",
      "    # Specify the time format (e.g., \"08:00\" or \"14:30\" would be %H:%M)\n",
      "    time_format = \"%H:%M\"\n",
      "    \n",
      "    # Convert 'selected observation period start' to datetime using the specified format\n",
      "    df['selected observation period start'] = pd.to_datetime(df['selected observation period start'], format=time_format, errors='coerce').dt.time\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category (we'll handle sorting by time in the next step)\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Standardize the observation period start\n",
      "df = standardize_observation_period_start(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "# Function to fix time format and ensure it has seconds (HH:MM:SS)\n",
      "def fix_time_format(df):\n",
      "    def format_time(value):\n",
      "        # If the value is already in HH:MM:SS, keep it as is\n",
      "        if isinstance(value, str) and len(value) == 5:  # Check for HH:MM format\n",
      "            return value + \":00\"  # Append :00 to make it HH:MM:SS\n",
      "        return value\n",
      "    \n",
      "    # Apply the time format function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category (we'll handle sorting by time in the next step)\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to fix the time format\n",
      "df = fix_time_format(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "\n",
      "# Function to fix time format and ensure it has seconds (HH:MM:SS)\n",
      "def fix_time_format(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, str):\n",
      "            if len(value) == 5:  # If it's in HH:MM format, append :00 to make it HH:MM:SS\n",
      "                return value + \":00\"\n",
      "        return value  # Keep everything else as is\n",
      "\n",
      "    # Apply the time format function to the column (only for string types)\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category (we'll handle sorting by time in the next step)\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to fix the time format\n",
      "df = fix_time_format(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "\n",
      "# Function to fix time format and ensure it has seconds (HH:MM:SS)\n",
      "def fix_time_format(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, str):\n",
      "            if len(value) == 5:  # If it's in HH:MM format, append :00 to make it HH:MM:SS\n",
      "                return value + \":00\"\n",
      "        return value  # Keep everything else as is\n",
      "\n",
      "    # Apply the time format function to the column (only for string types)\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category (we'll handle sorting by time in the next step)\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to fix the time format\n",
      "df = fix_time_format(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)  # Save without the index column\n",
      "import pandas as pd\n",
      "\n",
      "# Load the data\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "\n",
      "# Print the first 10 unique values in 'selected observation period start' to inspect the format\n",
      "print(df['selected observation period start'].unique()[:10])\n",
      "\n",
      "# Optional: Check data types in the DataFrame\n",
      "print(df.dtypes)\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM string\n",
      "        if isinstance(value, pd.Timestamp):  # If there are still any timestamp issues\n",
      "            return value.time().strftime(\"%H:%M\")\n",
      "        if isinstance(value, str):  # If it's a string, leave it as is or append :00 if necessary\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        if isinstance(value, datetime.time):  # Convert datetime.time to HH:MM:SS\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Save the processed DataFrame to inspect the changes\n",
      "df.to_excel(r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx', index=False)\n",
      "\n",
      "# Optional: Check the first few rows to verify changes\n",
      "print(df['selected observation period start'].head())\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Save the processed DataFrame to inspect the changes\n",
      "df.to_excel(r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx', index=False)\n",
      "\n",
      "# Optional: Check the first few rows to verify changes\n",
      "print(df['selected observation period start'].head()\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Save the processed DataFrame to inspect the changes\n",
      "df.to_excel(r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx', index=False)\n",
      "\n",
      "# Optional: Check the first few rows to verify changes\n",
      "print(df['selected observation period start'].head())\n",
      "import pandas as pd\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "import pandas as pd\n",
      "import datetime  # Import datetime to handle time objects\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "df.head()\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to separate sex ratio into male and female counts\n",
      "def separate_sex_ratio(df):\n",
      "    df[['present males', 'present females']] = df['present sex ratio'].str.split(';', expand=True)\n",
      "    # Convert the new columns to numeric for easier analysis\n",
      "    df['present males'] = pd.to_numeric(df['present males'], errors='coerce')\n",
      "    df['present females'] = pd.to_numeric(df['present females'], errors='coerce')\n",
      "    return df\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Save the processed DataFrame to inspect the changes\n",
      "df.to_excel(r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx', index=False)\n",
      "\n",
      "# Optional: Check the first few rows to verify changes\n",
      "print(df['selected observation period start'].head())\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column\n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the sex ratio separation function\n",
      "df = separate_sex_ratio(df)\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "# Add a column to store the original row order\n",
      "df['original_order'] = df.index\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column\n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "# Optional: Print out the first few rows to verify the result\n",
      "print(df_with_tide_categories_and_types.head())\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column\n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "# Optional: Print out the first few rows to verify the result\n",
      "print(df_with_tide_categories_and_types.head())\n",
      "import pandas as pd\n",
      "import datetime  # Import datetime to handle time objects\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "#df.head()\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Save the processed DataFrame to inspect the changes\n",
      "df.to_excel(r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx', index=False)\n",
      "\n",
      "# print(df['selected observation period start'].head())\n",
      "# Add a column to store the original row order\n",
      "df['original_order'] = df.index\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column\n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "# Optional: Print out the first few rows to verify the result\n",
      "print(df_with_tide_categories_and_types.head())\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column\n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "# Optional: Print out the first few rows to verify the result\n",
      "#print(df_with_tide_categories_and_types.head())\n",
      "import pandas as pd\n",
      "import datetime  # Import datetime to handle time objects\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "#df.head()\n",
      "import pandas as pd\n",
      "import datetime\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "#df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub\n",
      "\n",
      "# Fill NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Save the processed DataFrame to inspect the changes\n",
      "df.to_excel(r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx', index=False)\n",
      "\n",
      "# print(df['selected observation period start'].head())\n",
      "\n",
      "# Add a column to store the original row order\n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide categories (A/B) and types, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardize observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column\n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "# Optional: Print out the first few rows to verify the result\n",
      "#print(df_with_tide_categories_and_types.head())\n",
      "# DATA NV ADDITION (add NV and crab IDs to quantify crabs 'not visible' throughout each unique observation window) \n",
      "# Function to calculate NV crabs and concatenate the results\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide type, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide type', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_type, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide type': tide_type,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                # Append the NV row to the updated rows\n",
      "                updated_rows.append(nv_row)\n",
      "        \n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate the original data with the NV rows\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_post+NV.xlsx'\n",
      "df_with_nv.to_excel(output_path, index=False)\n",
      "# DATA NV ADDITION (add NV and crab IDs to quantify crabs 'not visible' throughout each unique observation window) \n",
      "\n",
      "# reset df as cleaned xlsx \n",
      "df = pd.read_excel(output_path)\n",
      "\n",
      "# Function to calculate NV crabs and concatenate the results\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide type, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide type', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_type, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide type': tide_type,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                # Append the NV row to the updated rows\n",
      "                updated_rows.append(nv_row)\n",
      "        \n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate the original data with the NV rows\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df)\n",
      "\n",
      "# Save the processed DataFrame to an Excel file\n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_post+NV.xlsx'\n",
      "df_with_nv.to_excel(output_path, index=False)\n",
      "# DATA NV ADDITION (add NV and crab IDs to quantify crabs 'not visible' throughout each unique observation window) \n",
      "\n",
      "# reset df as cleaned xlsx \n",
      "df = pd.read_excel(output_path)\n",
      "\n",
      "# Function to calculate NV crabs and concatenate the results\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                # Convert the nv_row dictionary into a DataFrame and append to updated_rows\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df)\n",
      "\n",
      "output_path_with_nv = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_NV_post.xlsx'\n",
      "df_with_nv.to_excel(output_path_with_nv, index=False)\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import datetime\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# DATA NV ADDITION (add NV and crab IDs to quantify crabs 'not visible' throughout each unique observation window) \n",
      "\n",
      "# reset df as cleaned xlsx \n",
      "df = pd.read_excel(output_path)\n",
      "\n",
      "# Function to calculate NV crabs and concatenate the results\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                # Convert the nv_row dictionary into a DataFrame and append to updated_rows\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df)\n",
      "\n",
      "output_path_with_nv = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_post_NV.xlsx'\n",
      "df_with_nv.to_excel(output_path_with_nv, index=False)\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# DATA NV ADDITION (add NV and crab IDs to quantify crabs 'not visible' throughout each unique observation window) \n",
      "\n",
      "# reset df as cleaned xlsx \n",
      "df = pd.read_excel(output_path)\n",
      "\n",
      "# Function to calculate NV crabs and concatenate the results\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                # Convert the nv_row dictionary into a DataFrame and append to updated_rows\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df)\n",
      "\n",
      "output_path_with_nv = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post+NV.xlsx'\n",
      "df_with_nv.to_excel(output_path_with_nv, index=False)\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import datetime\n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import datetime\n",
      "################################################ edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "###### Save df to xlsx \n",
      "#####output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "#####df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "###### Save df to xlsx \n",
      "#####output_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post.xlsx'\n",
      "#####df_with_tide_categories_and_types.to_excel(output_path, index=False)\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# DATA NV ADDITION (add NV and crab IDs to quantify crabs 'not visible' throughout each unique observation window) \n",
      "\n",
      "# reset df as cleaned xlsx \n",
      "dfnv = pd.read_excel(output_path)\n",
      "\n",
      "# Function to calculate NV crabs and concatenate the results\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = dfnv.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                # Convert the nv_row dictionary into a DataFrame and append to updated_rows\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_dfnv = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_dfnv\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(dfnv)\n",
      "\n",
      "# Save df to xlsx \n",
      "  # Append '_post+NV' before the extension\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "\n",
      "#######output_path_with_nv = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET_post+NV.xlsx'\n",
      "########df_with_nv.to_excel(output_path_with_nv, index=False)\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period, then filling 30 rows per NV).\n",
      "# Ensure correct column order in the output file\n",
      "output_column_order = [\n",
      "    'video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', \n",
      "    'present population', 'present sex ratio', 'present males', 'present females', \n",
      "    'selected observation period start', 'real time', 'observation minute from start', \n",
      "    'crab ID', 'sex', 'instantaneous behaviour', 'human visible?'\n",
      "]\n",
      "\n",
      "# Function to calculate NV crabs and maintain the column order\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N',  # Mark NV crabs as not visible\n",
      "                    'tide type': group['tide type'].iloc[0]  # Ensure tide type is carried over\n",
      "                }\n",
      "                # Convert the nv_row dictionary into a DataFrame and append to updated_rows\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Ensure the correct column order in the final DataFrame\n",
      "    nv_df = nv_df[output_column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the NV data to Excel with proper file path\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period, then filling 30 rows per NV).\n",
      "# Ensure correct column order in the output file\n",
      "output_column_order = [\n",
      "    'video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', \n",
      "    'present population', 'present sex ratio', 'present males', 'present females', \n",
      "    'selected observation period start', 'real time', 'observation minute from start', \n",
      "    'crab ID', 'sex', 'instantaneous behaviour', 'human visible?'\n",
      "]\n",
      "\n",
      "# Function to calculate NV crabs and maintain the column order\n",
      "def calculate_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "        \n",
      "        # If there are NV crabs to add, generate their IDs and behaviors\n",
      "        if num_nv > 0:\n",
      "            for i in range(1, num_nv + 1):\n",
      "                # Create a new row for each NV crab\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                    'sex': None,  # No sex specified for NV crabs\n",
      "                    'human visible?': 'N',  # Mark NV crabs as not visible\n",
      "                    'tide type': group['tide type'].iloc[0]  # Ensure tide type is carried over\n",
      "                }\n",
      "                # Convert the nv_row dictionary into a DataFrame and append to updated_rows\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Ensure the correct column order in the final DataFrame\n",
      "    nv_df = nv_df[output_column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the NV data to Excel with proper file path\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period, then filling 30 rows per NV).\n",
      "# Function to calculate NV crabs and assign correct sexes\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed crab counts by sex (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'M'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'F'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'selected observation period start': obs_start,\n",
      "                'crab ID': f'NV_M{i}',\n",
      "                'sex': 'M',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'present population': present_population,\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'human visible?': 'N',  # Mark NV crabs as not visible\n",
      "                'tide type': group['tide type'].iloc[0]  # Add tide type\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'selected observation period start': obs_start,\n",
      "                'crab ID': f'NV_F{i}',\n",
      "                'sex': 'F',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'present population': present_population,\n",
      "                'observation minute from start': None,\n",
      "                'human visible?': 'N',\n",
      "                'tide type': group['tide type'].iloc[0]  # Add tide type\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period, then filling 30 rows per NV).\n",
      "# Function to calculate NV crabs and assign correct sexes\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed crab counts by sex (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'M'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'F'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'selected observation period start': obs_start,\n",
      "                'crab ID': f'NV_M{i}',\n",
      "                'sex': 'M',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'present population': present_population,\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'human visible?': 'N',  # Mark NV crabs as not visible\n",
      "                'tide type': group['tide type'].iloc[0]  # Add tide type\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'selected observation period start': obs_start,\n",
      "                'crab ID': f'NV_F{i}',\n",
      "                'sex': 'F',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'present population': present_population,\n",
      "                'observation minute from start': None,\n",
      "                'human visible?': 'N',\n",
      "                'tide type': group['tide type'].iloc[0]  # Add tide type\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the NV data to Excel with proper file path\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period?).\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed crab counts by sex (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'M'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'F'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_M{i}',\n",
      "                'sex': 'M',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_F{i}',\n",
      "                'sex': 'F',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period?).\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'M'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'F'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_M{i}',\n",
      "                'sex': 'M',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_F{i}',\n",
      "                'sex': 'F',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period?).\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_M{i}',\n",
      "                'sex': 'M',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_F{i}',\n",
      "                'sex': 'F',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "###### new working 2/10. attempting to sort column order: (then sex designations, then filling columns, then full observation period?).\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_M{i}',\n",
      "                'sex': 'm',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_F{i}',\n",
      "                'sex': 'f',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "### trying to add 30 rows for NV. next is asking about the IDs of the existing NVs. \n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order with 30 rows per NV crab\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "## trying to remove NV redundancy \n",
      "\n",
      "df = pd.read_excel(output_path)\n",
      "\n",
      "# Extract the file name and extension from the previous output path\n",
      "file_name, file_extension = os.path.splitext(output_path)\n",
      "\n",
      "# Function to clean up NV crabs and remove redundant entries\n",
      "def clean_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with cleaned NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "\n",
      "        # If no crabs were observed, generate specific NV rows for all present crabs (NV_m1, NV_m2, etc.)\n",
      "        if num_observed == 0 and num_nv > 0:\n",
      "            # Generate NV crabs for the entire observation period\n",
      "            for i in range(1, present_population + 1):\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,\n",
      "                    'sex': None,\n",
      "                    'human visible?': 'N'\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "        \n",
      "        # If some crabs were observed, generate NV crabs for the remaining ones\n",
      "        elif num_observed > 0 and num_nv > 0:\n",
      "            # Generate NV crabs only for the missing ones\n",
      "            for i in range(1, num_nv + 1):\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,\n",
      "                    'sex': None,\n",
      "                    'human visible?': 'N'\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Append the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    cleaned_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return cleaned_df\n",
      "\n",
      "# Apply the function to clean the NV crabs\n",
      "df_cleaned = clean_nv_crabs(df)\n",
      "\n",
      "# Save the cleaned DataFrame to a new Excel file with the updated name\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_cleaned.to_excel(output_path_2, index=False)\n",
      "\n",
      "# Print the path to the saved file\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "## trying to remove NV redundancy \n",
      "\n",
      "df = pd.read_excel(output_path)\n",
      "\n",
      "# Extract the file name and extension from the previous output path\n",
      "file_name, file_extension = os.path.splitext(output_path)\n",
      "\n",
      "# Function to clean up NV crabs and remove redundant entries\n",
      "def clean_nv_crabs(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with cleaned NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        \n",
      "        # Get the unique observed crab IDs (excluding NV crabs)\n",
      "        observed_crabs = group.loc[group['instantaneous behaviour'] != 'NV', 'crab ID'].unique()\n",
      "        num_observed = len(observed_crabs)\n",
      "        \n",
      "        # Calculate the number of NV crabs\n",
      "        num_nv = present_population - num_observed\n",
      "\n",
      "        # If no crabs were observed, generate specific NV rows for all present crabs (NV_m1, NV_m2, etc.)\n",
      "        if num_observed == 0 and num_nv > 0:\n",
      "            # Generate NV crabs for the entire observation period\n",
      "            for i in range(1, present_population + 1):\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,\n",
      "                    'sex': None,\n",
      "                    'human visible?': 'N'\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "        \n",
      "        # If some crabs were observed, generate NV crabs for the remaining ones\n",
      "        elif num_observed > 0 and num_nv > 0:\n",
      "            # Generate NV crabs only for the missing ones\n",
      "            for i in range(1, num_nv + 1):\n",
      "                nv_row = {\n",
      "                    'video file': video_file,\n",
      "                    'tide category': tide_category,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'present population': present_population,\n",
      "                    'observation minute from start': None,\n",
      "                    'sex': None,\n",
      "                    'human visible?': 'N'\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_row]))\n",
      "\n",
      "        # Append the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    cleaned_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    return cleaned_df\n",
      "\n",
      "# Apply the function to clean the NV crabs\n",
      "df_cleaned = clean_nv_crabs(df)\n",
      "\n",
      "# Save the cleaned DataFrame to a new Excel file with the updated name\n",
      "output_path_2 = f\"{file_name}_+NV{file_extension}\"\n",
      "df_cleaned.to_excel(output_path_2, index=False)\n",
      "\n",
      "# Print the path to the saved file\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "### trying to add 30 rows for NV. next is asking about the IDs of the existing NVs. --> this worked! moving to next cell \n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order with 30 rows per NV crab\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV'\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# CALCULATE NV PRESENCE \n",
      "\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            nv_male_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_m{i}',\n",
      "                'sex': 'm',  # Assign male\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            nv_female_row = {\n",
      "                'video file': video_file,\n",
      "                'crabitat': group['crabitat'].iloc[0],\n",
      "                'season': group['season'].iloc[0],\n",
      "                'day type': group['day type'].iloc[0],\n",
      "                'tide category': tide_category,\n",
      "                'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                'present population': present_population,\n",
      "                'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                'present males': present_males,\n",
      "                'present females': present_females,\n",
      "                'selected observation period start': obs_start,\n",
      "                'real time': group['real time'].iloc[0],\n",
      "                'observation minute from start': None,  # NV crabs have no observed behavior\n",
      "                'crab ID': f'NV_f{i}',\n",
      "                'sex': 'f',  # Assign female\n",
      "                'instantaneous behaviour': 'NV',\n",
      "                'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "            }\n",
      "            updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "### trying to add 30 rows for NV. next is asking about the IDs of the existing NVs. --> this worked! moving to next cell \n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order with 30 rows per NV crab\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV'\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "### trying to add 30 rows for NV. next is asking about the IDs of the existing NVs. --> this worked! moving to next cell \n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order with 30 rows per NV crab\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV'\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# NEW NV combined ! 1841KB\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order with 30 rows per NV crab\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# NEW NV combined ! 1841KB\n",
      "# Function to calculate NV crabs, assign correct sexes, and maintain column/row order with 30 rows per NV crab\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV'\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "%history\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# NEW! DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Shift observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].apply(\n",
      "        lambda x: x + 1 if x < 30 else x  # Shift 0-29 to 1-30, leave 30 as is\n",
      "    )\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "# Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "# Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# NEW! DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Shift observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].apply(\n",
      "        lambda x: x + 1 if x < 30 else x  # Shift 0-29 to 1-30, leave 30 as is\n",
      "    )\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "# Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "# Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# NEW! DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Shift observation minute from start (0-29 to 1-30)\n",
      "    if df['observation minute from start'].min() >= 0 and df['observation minute from start'].max() <= 29:\n",
      "        df['observation minute from start'] = df['observation minute from start'] + 1\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "# Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "# Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# NEW! DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Shift observation minute from start (0-29 to 1-30) only for those that start with 0\n",
      "    df['observation minute from start'] = df['observation minute from start'].apply(lambda x: x + 1 if x < 30 else x)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "# Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "# Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# NEW! DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# NEW! DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        # If it's a datetime.time object, convert it to HH:MM:SS string\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        # If it's a string, ensure it's in HH:MM:SS format (append :00 if necessary)\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value  # Leave anything else unchanged\n",
      "\n",
      "    # Apply the function to the column\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Standardise observation minute from start (0-29 to 1-30)\n",
      "    df['observation minute from start'] = df['observation minute from start'].replace(0, 1)\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            # Determine whether it's high or low tide\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "   # Split the file path into name and extension\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "   # Append '_post' before the extension \n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "## optional sanity check\n",
      "##print(df_with_tide_categories_and_types.head())\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame by video file, tide category, and observation minute\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(\n",
      "    by=['video file', 'tide category', 'observation minute from start']\n",
      ")\n",
      "\n",
      "# Reorder columns to place 'tide type' after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "# Remove 'tide type' from its current position\n",
      "columns_order.remove('tide type')\n",
      "# Insert 'tide type' after 'tide category'\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame with the new columns order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# DATA VALIDATION (_post+NV)\n",
      "\n",
      "def validate_data(df):\n",
      "    # Create a summary DataFrame to store validation results\n",
      "    validation_results = pd.DataFrame(columns=['video file', 'tide category', 'expected rows', 'actual rows', 'missing rows'])\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result\n",
      "        validation_results = validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        }, ignore_index=True)\n",
      "\n",
      "        # Check for duplicates\n",
      "        if group.duplicated().any():\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "\n",
      "    # Check for NaN values in critical columns\n",
      "    nan_columns = ['video file', 'tide category', 'present population']\n",
      "    for column in nan_columns:\n",
      "        if df[column].isnull().any():\n",
      "            print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "    # Check observation minute range\n",
      "    if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "        print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Return validation results\n",
      "    return validation_results\n",
      "\n",
      "# Run data validation\n",
      "validation_summary = validate_data(df_with_nv)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates\n",
      "        if group.duplicated().any():\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "\n",
      "    # Check for NaN values in critical columns\n",
      "    nan_columns = ['video file', 'tide category', 'present population']\n",
      "    for column in nan_columns:\n",
      "        if df[column].isnull().any():\n",
      "            print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "    # Check observation minute range\n",
      "    if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "        print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Run data validation\n",
      "validation_summary = validate_data(df_with_nv)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates\n",
      "        if group.duplicated().any():\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "\n",
      "    # Check for NaN values in critical columns\n",
      "    nan_columns = ['video file', 'tide category', 'present population']\n",
      "    for column in nan_columns:\n",
      "        if df[column].isnull().any():\n",
      "            print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "    # Check observation minute range\n",
      "    if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "        print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Run data validation\n",
      "validation_summary = validate_data(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "#validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "#validation_summary.to_excel(validation_summary_path, index=False)\n",
      "#print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates\n",
      "        if group.duplicated().any():\n",
      "            duplicates = group[group.duplicated(keep=False)]  # Get all duplicate rows\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "\n",
      "    # Check for NaN values in critical columns\n",
      "    nan_columns = ['video file', 'tide category', 'present population']\n",
      "    for column in nan_columns:\n",
      "        if df[column].isnull().any():\n",
      "            print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "    # Check observation minute range\n",
      "    if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "        print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "#validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "#validation_summary.to_excel(validation_summary_path, index=False)\n",
      "#print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates\n",
      "        if group.duplicated().any():\n",
      "            duplicates = group[group.duplicated(keep=False)]  # Get all duplicate rows\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "\n",
      "    # Check for NaN values in critical columns\n",
      "    nan_columns = ['video file', 'tide category', 'present population']\n",
      "    for column in nan_columns:\n",
      "        if df[column].isnull().any():\n",
      "            print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "    # Check observation minute range\n",
      "    if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "        print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "#validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "#validation_summary.to_excel(validation_summary_path, index=False)\n",
      "#print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        if group.duplicated(subset=duplicate_columns).any():\n",
      "            duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "    # Check for NaN values in critical columns\n",
      "    nan_columns = ['video file', 'tide category', 'present population']\n",
      "    for column in nan_columns:\n",
      "        if df[column].isnull().any():\n",
      "            print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "    # Check observation minute range\n",
      "    if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "        print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "\n",
      "# Save validation summary to Excel\n",
      "#validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "#validation_summary.to_excel(validation_summary_path, index=False)\n",
      "#print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "        else:\n",
      "            print(f\"No duplicates found in {video_file} - {tide_category}.\")\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "#validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "#validation_summary.to_excel(validation_summary_path, index=False)\n",
      "#print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Data Validation Function\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "        else:\n",
      "            print(f\"No duplicates found in {video_file} - {tide_category}.\")\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# better validation script, that was intended before NV but doesnt have the rigt calcuation fo rhtis. maybe its better than the above output?\n",
      "# DATA VALIDATION (_post)\n",
      "\n",
      "# Validate that each crab ID has 30 rows\n",
      "def validate_crab_ids(df):\n",
      "    # Count the number of rows for each crab ID\n",
      "    crab_counts = df['crab ID'].value_counts()\n",
      "\n",
      "    # Identify crab IDs that do not have 30 rows\n",
      "    invalid_crabs = crab_counts[crab_counts != 30]\n",
      "\n",
      "    if invalid_crabs.empty:\n",
      "        print(\"All crab IDs have 30 rows.\")\n",
      "    else:\n",
      "        print(\"The following crab IDs do not have 30 rows:\")\n",
      "        for crab_id, count in invalid_crabs.items():\n",
      "            print(f\"Crab ID: {crab_id} - Count: {count}\")\n",
      "\n",
      "# Call the validation function\n",
      "validate_crab_ids(df_with_tide_categories_and_types)\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# better validation post second \n",
      "def validate_data_post_nv(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30  # Adjusted for post addition of NVs\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "        else:\n",
      "            print(f\"No duplicates found in {video_file} - {tide_category}.\")\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if group[column].isnull().any():  # Change df to group to check within the group\n",
      "                print(f\"NaN values found in column '{column}' for {video_file} - {tide_category}.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((group['observation minute from start'] >= 1).all() and (group['observation minute from start'] <= 30).all()):\n",
      "            print(f\"Observation minutes out of expected range (1-30) in {video_file} - {tide_category}.\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Perform the validation\n",
      "validation_summary = validate_data_post_nv(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# better validation post second \n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# better validation post second \n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame by video file, tide category, and observation minute\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(\n",
      "    by=['video file', 'tide category', 'observation minute from start']\n",
      ")\n",
      "\n",
      "# Reorder columns to place 'tide type' after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "# Remove 'tide type' from its current position\n",
      "columns_order.remove('tide type')\n",
      "# Insert 'tide type' after 'tide category'\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame with the new columns order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_issues = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "validation_issues.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_results = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "validation_results.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# CALCULATE NV PRESENCE (assign correct sexes, and maintain column/row order with 30 rows per NV crab (i.e., full obs window)) \n",
      "\n",
      "# Function to calculate NV crabs\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV' - i.e., obs windows where no one showed \n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# CALCULATE NV PRESENCE (assign correct sexes, and maintain column/row order with 30 rows per NV crab (i.e., full obs window)) \n",
      "\n",
      "# Function to calculate NV crabs\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV' - i.e., obs windows where no one showed \n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# better validation post second \n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "## copy including potential fix \n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # No longer shifting the observation minutes here\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list, keeping crab IDs intact\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "## copy including potential fix \n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # No longer shifting the observation minutes here\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list, keeping crab IDs intact\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'low' if 'low' in tide_category else 'high'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 1: Identify unique observation periods where the first row of 'observation minute from start' is 0\n",
      "observation_periods_with_zero_start = df_with_tide_categories_and_types.groupby(\n",
      "    ['video file', 'tide category']).filter(lambda x: x['observation minute from start'].iloc[0] == 0)\n",
      "\n",
      "# Step 2: Reassign ONLY the 'observation minute from start' column for these identified periods by adding 1\n",
      "df_with_tide_categories_and_types.loc[\n",
      "    observation_periods_with_zero_start.index, 'observation minute from start'] += 1\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 1: Identify unique observation periods where the first row of 'observation minute from start' is 0\n",
      "observation_periods_with_zero_start = df_with_tide_categories_and_types.groupby(\n",
      "    ['video file', 'tide category']).filter(lambda x: x['observation minute from start'].iloc[0] == 0)\n",
      "\n",
      "# Step 2: Reassign ONLY the 'observation minute from start' column for these identified periods by adding 1\n",
      "df_with_tide_categories_and_types.loc[\n",
      "    observation_periods_with_zero_start.index, 'observation minute from start'] += 1\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Function to assign tide types (high/low A/B for tub) from tide categories, and standardize observation times\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Check if observation minutes are from 0-29\n",
      "            if (group['observation minute from start'] >= 0).all() and (group['observation minute from start'] <= 29).all():\n",
      "                # Shift the minutes by +1 for this window\n",
      "                group['observation minute from start'] = group['observation minute from start'] + 1\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 1: Identify unique observation periods where the first row of 'observation minute from start' is 0\n",
      "observation_periods_with_zero_start = df_with_tide_categories_and_types.groupby(\n",
      "    ['video file', 'tide category']).filter(lambda x: x['observation minute from start'].iloc[0] == 0)\n",
      "\n",
      "# Step 2: Reassign ONLY the 'observation minute from start' column for these identified periods by adding 1\n",
      "df_with_tide_categories_and_types.loc[\n",
      "    observation_periods_with_zero_start.index, 'observation minute from start'] += 1\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify unique observation periods where the 'observation minute from start' contains a 0 at any point\n",
      "observation_periods_with_zero_start = df_with_tide_categories_and_types.groupby(\n",
      "    ['video file', 'tide category']).filter(lambda x: (x['observation minute from start'] == 0).any())\n",
      "\n",
      "# Step 3: Reassign ONLY the 'observation minute from start' column for these identified periods by adding 1\n",
      "df_with_tide_categories_and_types.loc[\n",
      "    df_with_tide_categories_and_types.index.isin(observation_periods_with_zero_start.index), \n",
      "    'observation minute from start'\n",
      "] = df_with_tide_categories_and_types['observation minute from start'] + 1\n",
      "\n",
      "# Ensure no zeros remain in the 'observation minute from start' column\n",
      "zeros_remaining = df_with_tide_categories_and_types[df_with_tide_categories_and_types['observation minute from start'] == 0]\n",
      "if not zeros_remaining.empty:\n",
      "    print(\"Warning: Zeros still found in observation minute from start column.\")\n",
      "    print(zeros_remaining)\n",
      "\n",
      "# Sort the DataFrame back to the original order\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save df to xlsx \n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "\n",
      "# Optional sanity check\n",
      "# print(df_with_tide_categories_and_types.head())\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
      "def shift_observation_minutes(df):\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # If an observation window starts with 0, shift the whole group by +1\n",
      "        if group['observation minute from start'].min() == 0:\n",
      "            df.loc[group.index, 'observation minute from start'] += 1\n",
      "            \n",
      "            # Check if any minutes go from 0-30 now and remove the extra 31st minute\n",
      "            if group['observation minute from start'].max() == 31:\n",
      "                df = df.drop(group[group['observation minute from start'] == 31].index)\n",
      "\n",
      "    return df\n",
      "\n",
      "# Apply the observation minute shifting function\n",
      "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
      "\n",
      "# Step 3: Sort and Reorder Columns\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Ensure 'tide type' is after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "columns_order.remove('tide type')\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Save the cleaned DataFrame to Excel\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
      "def shift_observation_minutes(df):\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # If an observation window starts with 0, shift the whole group by +1\n",
      "        if group['observation minute from start'].min() == 0:\n",
      "            df.loc[group.index, 'observation minute from start'] += 1\n",
      "\n",
      "    # Check and remove rows with observation minute 31\n",
      "    df = df[df['observation minute from start'] <= 30]\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Apply the observation minute shifting function\n",
      "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
      "\n",
      "# Step 3: Sort and Reorder Columns\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by='original_order')\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Ensure 'tide type' is after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "columns_order.remove('tide type')\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Save the cleaned DataFrame to Excel\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
      "def shift_observation_minutes(df):\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # If an observation window starts with 0, shift the whole group by +1\n",
      "        if group['observation minute from start'].min() == 0:\n",
      "            df.loc[group.index, 'observation minute from start'] += 1\n",
      "\n",
      "    # Check and remove rows with observation minute 31\n",
      "    df = df[df['observation minute from start'] <= 30]\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Apply the observation minute shifting function\n",
      "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
      "\n",
      "# Step 3: Sort by video file, tide category, and observation minute from start\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by=['video file', 'tide category', 'observation minute from start'])\n",
      "\n",
      "# Step 4: Reorder Columns to place 'tide type' after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "columns_order.remove('tide type')\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the cleaned DataFrame to Excel\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "# new DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
      "def shift_observation_minutes(df):\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # If an observation window starts with 0, shift the whole group by +1\n",
      "        if group['observation minute from start'].min() == 0:\n",
      "            df.loc[group.index, 'observation minute from start'] += 1\n",
      "\n",
      "    # Check and remove rows with observation minute 31\n",
      "    df = df[df['observation minute from start'] <= 30]\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Apply the observation minute shifting function\n",
      "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
      "\n",
      "# Step 3: Sort by video file, tide category, and observation minute from start\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by=['video file', 'tide category', 'observation minute from start'])\n",
      "\n",
      "# Step 4: Reorder Columns to place 'tide type' after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "columns_order.remove('tide type')\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the cleaned DataFrame to Excel\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation_summary.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# CALCULATE NV PRESENCE (assign correct sexes, and maintain column/row order with 30 rows per NV crab (i.e., full obs window)) \n",
      "\n",
      "# Function to calculate NV crabs\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV' - i.e., obs windows where no one showed \n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# Function to validate the counts of each video file + tide category combination\n",
      "def validate_counts(df):\n",
      "    # Create a DataFrame to hold expected counts\n",
      "    expected_counts = df.groupby(['video file', 'tide category']).size().reset_index(name='expected_count')\n",
      "\n",
      "    # Create a DataFrame for the actual counts\n",
      "    actual_counts = df.groupby(['video file', 'tide category']).size().reset_index(name='actual_count')\n",
      "\n",
      "    # Merge the expected and actual counts\n",
      "    validation_df = pd.merge(expected_counts, actual_counts, on=['video file', 'tide category'], how='outer')\n",
      "\n",
      "    # Check for discrepancies\n",
      "    validation_df['discrepancy'] = validation_df['expected_count'] - validation_df['actual_count']\n",
      "\n",
      "    # Print the validation results\n",
      "    for index, row in validation_df.iterrows():\n",
      "        if row['discrepancy'] != 0:\n",
      "            print(f\"Validation issue for {row['video file']} + {row['tide category']}: \"\n",
      "                  f\"Expected {row['expected_count']} rows, found {row['actual_count']} rows. \"\n",
      "                  f\"Discrepancy: {row['discrepancy']}\")\n",
      "\n",
      "    return validation_df\n",
      "\n",
      "# Apply validation\n",
      "validation_results = validate_counts(df_with_tide_categories_and_types)\n",
      "\n",
      "# Optional: Display the validation results\n",
      "print(validation_results)\n",
      "# DATA VALIDATION (_post) (30obs/crabID + NV)\n",
      "def validate_crab_id_rows_with_nv(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        original_count = 30  # Original expected count\n",
      "        nv_count = group['crab ID'].str.contains('NV_').sum()  # Count NV rows\n",
      "        \n",
      "        # Calculate expected count as original plus NV\n",
      "        expected_count = original_count + nv_count\n",
      "        actual_count = len(group)\n",
      "\n",
      "        if actual_count != expected_count:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'expected count': expected_count,\n",
      "                'actual count': actual_count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows_with_nv(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} \"\n",
      "              f\"expected {issue['expected count']} rows, but found {issue['actual count']}.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows in each observation window, including NV.\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID + NV)\n",
      "# DATA VALIDATION (_post) (30obs/crabID + NV)\n",
      "def validate_crab_id_rows_with_nv(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        original_count = 30  # Original expected count\n",
      "        # Convert crab ID to string and count NV rows\n",
      "        nv_count = group['crab ID'].astype(str).str.contains('NV_').sum()  \n",
      "        \n",
      "        # Calculate expected count as original plus NV\n",
      "        expected_count = original_count + nv_count\n",
      "        actual_count = len(group)\n",
      "\n",
      "        if actual_count != expected_count:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'expected count': expected_count,\n",
      "                'actual count': actual_count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows_with_nv(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} \"\n",
      "              f\"expected {issue['expected count']} rows, but found {issue['actual count']}.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows in each observation window, including NV.\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if group[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((group['observation minute from start'] >= 1).all() and (group['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Call the new crab ID validation function\n",
      "    crab_id_validation_results = validate_crab_id_rows_with_nv(df)\n",
      "\n",
      "    # If there are validation issues with crab IDs, print them\n",
      "    if crab_id_validation_results:\n",
      "        print(\"Validation issues found with crab IDs:\")\n",
      "        for issue in crab_id_validation_results:\n",
      "            print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} \"\n",
      "                  f\"expected {issue['expected count']} rows, but found {issue['actual count']}.\")\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary_df = validate_data(df_with_tide_categories_and_types)\n",
      "validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = group.shape[0]  # Count actual rows in the group\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, print details\n",
      "        if not duplicates.empty:\n",
      "            print(f\"Duplicates found in {video_file} - {tide_category}.\")\n",
      "            print(duplicates)  # Print the duplicated rows\n",
      "            print(\"Duplicate indices:\", duplicates.index.tolist())  # Print indices of duplicates\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if group[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((group['observation minute from start'] >= 1).all() and (group['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Call the crab ID validation function and get issues\n",
      "    crab_id_validation_issues = validate_crab_id_rows_with_nv(df)\n",
      "\n",
      "    # If there are validation issues with crab IDs, print them\n",
      "    if crab_id_validation_issues:\n",
      "        print(\"Validation issues found with crab IDs:\")\n",
      "        for issue in crab_id_validation_issues:\n",
      "            print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} \"\n",
      "                  f\"expected {issue['expected count']} rows, but found {issue['actual count']}.\")\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Example call to save the validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary_df = validate_data(df_with_tide_categories_and_types)\n",
      "validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    duplicate_rows = []  # To store duplicates information\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        actual_rows = len(group)  # Count actual rows in the group\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, add them to the duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicate_rows.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicates as a list of records\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if group[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((group['observation minute from start'] >= 1).all() and (group['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Convert duplicate rows to a DataFrame\n",
      "    if duplicate_rows:\n",
      "        duplicates_df = pd.DataFrame(duplicate_rows)\n",
      "    else:\n",
      "        duplicates_df = pd.DataFrame(columns=['video file', 'tide category', 'duplicates'])\n",
      "\n",
      "    # Combine validation results and duplicates into a single DataFrame\n",
      "    combined_validation_df = pd.merge(validation_results_df, duplicates_df, \n",
      "                                       on=['video file', 'tide category'], how='left')\n",
      "\n",
      "    # Call the crab ID validation function and get issues\n",
      "    crab_id_validation_issues = validate_crab_id_rows_with_nv(df)\n",
      "\n",
      "    # If there are validation issues with crab IDs, print them\n",
      "    if crab_id_validation_issues:\n",
      "        print(\"Validation issues found with crab IDs:\")\n",
      "        for issue in crab_id_validation_issues:\n",
      "            print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} \"\n",
      "                  f\"expected {issue['expected count']} rows, but found {issue['actual count']}.\")\n",
      "\n",
      "    # Save combined validation summary to CSV\n",
      "    validation_summary_path = f\"{file_name}_post+NV_validation_summary.csv\"\n",
      "    combined_validation_df.to_csv(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "    return combined_validation_df\n",
      "\n",
      "# execute the validation\n",
      "validation_summary_df = validate_data(df_with_tide_categories_and_types)\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    duplicate_rows = []  # To store duplicates information\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual number of unique combinations of video file and tide category\n",
      "        actual_rows = len(group)\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, add them to the duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicate_rows.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicates as a list of records\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if group[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((group['observation minute from start'] >= 1).all() and (group['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Convert duplicate rows to a DataFrame\n",
      "    if duplicate_rows:\n",
      "        duplicates_df = pd.DataFrame(duplicate_rows)\n",
      "    else:\n",
      "        duplicates_df = pd.DataFrame(columns=['video file', 'tide category', 'duplicates'])\n",
      "\n",
      "    # Combine validation results and duplicates into a single DataFrame\n",
      "    combined_validation_df = pd.merge(validation_results_df, duplicates_df, \n",
      "                                       on=['video file', 'tide category'], how='left')\n",
      "\n",
      "    # Call the crab ID validation function and get issues\n",
      "    crab_id_validation_issues = validate_crab_id_rows_with_nv(df)\n",
      "\n",
      "    # If there are validation issues with crab IDs, print them\n",
      "    if crab_id_validation_issues:\n",
      "        print(\"Validation issues found with crab IDs:\")\n",
      "        for issue in crab_id_validation_issues:\n",
      "            print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} \"\n",
      "                  f\"expected {issue['expected count']} rows, but found {issue['actual count']}.\")\n",
      "\n",
      "    # Save combined validation summary to CSV\n",
      "    validation_summary_path = f\"{file_name}_post+NV_validation_summary.csv\"\n",
      "    combined_validation_df.to_csv(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "    return combined_validation_df\n",
      "\n",
      "# Example call to execute the validation\n",
      "validation_summary_df = validate_data(df_with_tide_categories_and_types)\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    duplicates_info = []  # To store information about duplicates\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual number of rows based on unique combinations\n",
      "        actual_rows = group.shape[0]  # Total rows in the group\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, save details\n",
      "        if not duplicates.empty:\n",
      "            duplicates_info.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates[['selected observation period start', 'observation minute from start', 'crab ID']].to_dict(orient='records')\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Create a DataFrame for duplicates info\n",
      "    duplicates_df = pd.DataFrame(duplicates_info)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary, duplicates_summary = validate_data(df)\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "\n",
      "duplicates_summary_path = f\"{file_name}_post+NV_duplicates_summary.xlsx\"\n",
      "duplicates_summary.to_excel(duplicates_summary_path, index=False)\n",
      "\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "print(f\"Duplicates summary saved to: {duplicates_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    duplicates_info = []  # To store information about duplicates\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual number of rows based on unique combinations\n",
      "        actual_rows = group.shape[0]  # Total rows in the group\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, save details\n",
      "        if not duplicates.empty:\n",
      "            duplicates_info.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates[['selected observation period start', 'observation minute from start', 'crab ID']].to_dict(orient='records')\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Create a DataFrame for duplicates info\n",
      "    duplicates_df = pd.DataFrame(duplicates_info)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary, duplicates_summary = validate_data(df)\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "\n",
      "duplicates_summary_path = f\"{file_name}_post+NV_duplicates_summary.xlsx\"\n",
      "duplicates_summary.to_excel(duplicates_summary_path, index=False)\n",
      "\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "print(f\"Duplicates summary saved to: {duplicates_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    duplicate_rows = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations of video file and tide category\n",
      "        actual_rows = group.shape[0]\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, store them\n",
      "        if not duplicates.empty:\n",
      "            duplicate_rows.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicates as a list of dictionaries\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "\n",
      "    # Save duplicates into a DataFrame if any were found\n",
      "    if duplicate_rows:\n",
      "        duplicates_df = pd.DataFrame(duplicate_rows)\n",
      "        duplicates_summary_path = f\"{file_name}_post+NV_duplicates_summary.csv\"\n",
      "        duplicates_df.to_csv(duplicates_summary_path, index=False)\n",
      "        print(f\"Duplicate summary saved to: {duplicates_summary_path}\")\n",
      "\n",
      "    return validation_results_df\n",
      "\n",
      "# Usage example\n",
      "validation_summary = validate_data(df_with_tide_categories_and_types)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    # Keep track of duplicates\n",
      "    duplicates_list = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations\n",
      "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
      "\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, append to duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicates_list.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Save duplicates if any\n",
      "    duplicates_df = pd.DataFrame(duplicates_list)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(\"Duplicates found:\")\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Use the validation function and save outputs\n",
      "validation_summary, duplicates = validate_data(df)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_post+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# DATA VALIDATION (_post+NV)\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    # Keep track of duplicates\n",
      "    duplicates_list = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations\n",
      "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
      "\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, append to duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicates_list.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Save duplicates if any\n",
      "    duplicates_df = pd.DataFrame(duplicates_list)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(\"Duplicates found:\")\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Use the validation function and save outputs\n",
      "validation_summary, duplicates = validate_data(df)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_post+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# Debugging: Print the original DataFrame\n",
      "print(\"Original DataFrame:\")\n",
      "print(df.head())  # Show first few rows for context\n",
      "print(df[['video file', 'tide category', 'present population']].info())  # Show data types and non-null counts\n",
      "\n",
      "# Group by video file and tide category for debugging\n",
      "grouped = df.groupby(['video file', 'tide category'])\n",
      "print(\"Grouped DataFrame:\")\n",
      "for (video_file, tide_category), group in grouped:\n",
      "    print(f\"\\nGroup for {video_file} - {tide_category}:\")\n",
      "    print(group)  # Show the content of the group\n",
      "    print(f\"Number of rows in this group: {group.shape[0]}\")\n",
      "# Ensure the DataFrame you're validating is the most recent one\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned DataFrame including NVs saved to: {output_path_2}\")\n",
      "\n",
      "# Validate the cleaned DataFrame\n",
      "validation_summary, duplicates = validate_data(df_with_nv)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation_summary.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_post+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# DATA VALIDATION (_post+NV) (30obs/crabID + NV)\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "df = df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    # Keep track of duplicates\n",
      "    duplicates_list = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations\n",
      "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
      "\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, append to duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicates_list.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Save duplicates if any\n",
      "    duplicates_df = pd.DataFrame(duplicates_list)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(\"Duplicates found:\")\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Use the validation function and save outputs\n",
      "validation_summary, duplicates = validate_data(df)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_post+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# DATA VALIDATION (_post+NV) (30obs/crabID + NV)\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    # Keep track of duplicates\n",
      "    duplicates_list = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations\n",
      "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
      "\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, append to duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicates_list.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Filter out results with 0 missing rows\n",
      "    validation_results_df = validation_results_df[validation_results_df['missing rows'] != 0]\n",
      "\n",
      "    # Save duplicates if any\n",
      "    duplicates_df = pd.DataFrame(duplicates_list)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(\"Duplicates found:\")\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Use the validation function and save outputs\n",
      "validation_summary, duplicates = validate_data(df)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_post+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
      "def shift_observation_minutes(df):\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # If an observation window starts with 0, shift the whole group by +1\n",
      "        if group['observation minute from start'].min() == 0:\n",
      "            df.loc[group.index, 'observation minute from start'] += 1\n",
      "\n",
      "    # Check and remove rows with observation minute 31\n",
      "    df = df[df['observation minute from start'] <= 30]\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Apply the observation minute shifting function\n",
      "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
      "\n",
      "# Step 3: Sort by video file, tide category, and observation minute from start\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by=['video file', 'tide category', 'observation minute from start'])\n",
      "\n",
      "# Step 4: Reorder Columns to place 'tide type' after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "columns_order.remove('tide type')\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the cleaned DataFrame to Excel\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_post{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "# DATA VALIDATION (_post) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_post_validation.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# CALCULATE NV PRESENCE (assign correct sexes, and maintain column/row order with 30 rows per NV crab (i.e., full obs window)) \n",
      "\n",
      "# Function to calculate NV crabs\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV' - i.e., obs windows where no one showed \n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_post+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# DATA VALIDATION (_post+NV) (30obs/crabID + NV)\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    # Keep track of duplicates\n",
      "    duplicates_list = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations\n",
      "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
      "\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, append to duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicates_list.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Filter out results with 0 missing rows\n",
      "    validation_results_df = validation_results_df[validation_results_df['missing rows'] != 0]\n",
      "\n",
      "    # Save duplicates if any\n",
      "    duplicates_df = pd.DataFrame(duplicates_list)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(\"Duplicates found:\")\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Use the validation function and save outputs\n",
      "validation_summary, duplicates = validate_data(df)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_post+NV_validation.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_post+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# Python script for creating an activity budget for Afruca tangeri, from instantaneous observations of two SWC crabitats (110 tank & tub) throughout 2022-2023. Composed by s.titus@ucl.ac.uk 1 October 2024\n",
      "\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "#################################################################### edit here when graduating from subset to final data \n",
      "file_path = r'C:\\Users\\Sanna\\Desktop\\husbandry-article_SUBSET.xlsx'\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
      "####################################################################\n",
      "## optional sanity check\n",
      "##df.head()\n",
      "# DATA CLEANING (fill human visible column, format time, save the order for df integrity, assign high/low A/B tide type for the tub)\n",
      "\n",
      "# Fill any NaNs in the 'human visible?' column with 'N'\n",
      "df['human visible?'] = df['human visible?'].fillna('N')\n",
      "\n",
      "# Function to normalize 'selected observation period start' column\n",
      "def normalize_observation_period_start(df):\n",
      "    def format_time(value):\n",
      "        if isinstance(value, datetime.time):\n",
      "            return value.strftime(\"%H:%M:%S\")\n",
      "        if isinstance(value, str):\n",
      "            return value if len(value) == 8 else value + \":00\"\n",
      "        return value\n",
      "\n",
      "    df['selected observation period start'] = df['selected observation period start'].apply(format_time)\n",
      "    return df\n",
      "\n",
      "# Normalize the 'selected observation period start' column\n",
      "df = normalize_observation_period_start(df)\n",
      "\n",
      "# Add a column to store the original row order prior to tide category creation \n",
      "df['original_order'] = df.index\n",
      "\n",
      "# Step 1: Assign Tide Categories and Types\n",
      "def assign_tide_categories_and_types(df):\n",
      "    updated_rows = []  # Placeholder for updated rows\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Check if it's tub data for high/low A and B\n",
      "        if 'tub' in video_file:\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type  # Assign tide type\n",
      "            \n",
      "            # Sort by observation period start to rank them properly\n",
      "            group = group.sort_values(by='selected observation period start')\n",
      "\n",
      "            # Rank the observations within each tide category\n",
      "            group['tide category rank'] = group.groupby('selected observation period start').ngroup() + 1\n",
      "\n",
      "            # Assign A or B based on the rank (1 = A, 2 = B)\n",
      "            group['tide category'] = tide_category + \" \" + group['tide category rank'].map({1: 'A', 2: 'B'})\n",
      "\n",
      "        else:  # For tank data, just assign high or low\n",
      "            tide_type = 'high' if 'high' in tide_category else 'low'\n",
      "            group['tide type'] = tide_type\n",
      "            group['tide category'] = tide_category  # Keep the original category\n",
      "\n",
      "        # Append the updated group to the list\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows into a single DataFrame\n",
      "    updated_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Drop the extra 'tide category rank' column \n",
      "    updated_df = updated_df.drop(columns=['tide category rank'], errors='ignore')\n",
      "\n",
      "    return updated_df\n",
      "\n",
      "# Apply the function to assign tide categories and types\n",
      "df_with_tide_categories_and_types = assign_tide_categories_and_types(df)\n",
      "\n",
      "# Step 2: Identify and Adjust 0-Start Observation Periods\n",
      "def shift_observation_minutes(df):\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # If an observation window starts with 0, shift the whole group by +1\n",
      "        if group['observation minute from start'].min() == 0:\n",
      "            df.loc[group.index, 'observation minute from start'] += 1\n",
      "\n",
      "    # Check and remove rows with observation minute 31\n",
      "    df = df[df['observation minute from start'] <= 30]\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Apply the observation minute shifting function\n",
      "df_with_tide_categories_and_types = shift_observation_minutes(df_with_tide_categories_and_types)\n",
      "\n",
      "# Step 3: Sort by video file, tide category, and observation minute from start\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.sort_values(by=['video file', 'tide category', 'observation minute from start'])\n",
      "\n",
      "# Step 4: Reorder Columns to place 'tide type' after 'tide category'\n",
      "columns_order = list(df_with_tide_categories_and_types.columns)\n",
      "columns_order.remove('tide type')\n",
      "tide_category_index = columns_order.index('tide category') + 1\n",
      "columns_order.insert(tide_category_index, 'tide type')\n",
      "\n",
      "# Reorder the DataFrame\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types[columns_order]\n",
      "\n",
      "# Drop the 'original_order' column after sorting\n",
      "df_with_tide_categories_and_types = df_with_tide_categories_and_types.drop(columns=['original_order'])\n",
      "\n",
      "# Save the cleaned DataFrame to Excel\n",
      "file_name, file_extension = os.path.splitext(file_path)\n",
      "output_path_1 = f\"{file_name}_cleaned{file_extension}\" \n",
      "df_with_tide_categories_and_types.to_excel(output_path_1, index=False)\n",
      "print(f\"Cleaned dataset saved to: {output_path_1}\")\n",
      "# DATA VALIDATION (_cleaned) (30obs/crabID)\n",
      "\n",
      "# Check that each crab ID has exactly 30 rows in each observation window\n",
      "def validate_crab_id_rows(df):\n",
      "    # Group by video file, tide category, and crab ID\n",
      "    grouped = df.groupby(['video file', 'tide category', 'crab ID'])\n",
      "\n",
      "    # Create a list to hold any validation issues\n",
      "    validation_issues = []\n",
      "\n",
      "    # Iterate through the groups and check row counts\n",
      "    for (video_file, tide_category, crab_id), group in grouped:\n",
      "        count = len(group)\n",
      "        if count != 30:\n",
      "            validation_issues.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'crab ID': crab_id,\n",
      "                'row count': count\n",
      "            })\n",
      "\n",
      "    return validation_issues\n",
      "\n",
      "# Perform validation\n",
      "validation_results = validate_crab_id_rows(df_with_tide_categories_and_types)\n",
      "\n",
      "# Output the validation results\n",
      "if validation_results:\n",
      "    print(\"Validation issues found:\")\n",
      "    for issue in validation_results:\n",
      "        print(f\"Crab ID: {issue['crab ID']} in {issue['video file']} - {issue['tide category']} has {issue['row count']} rows.\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "\n",
      "# Save validation summary to Excel\n",
      "if validation_results:\n",
      "    # Convert validation issues into a DataFrame\n",
      "    validation_summary_df = pd.DataFrame(validation_results)\n",
      "    \n",
      "    # Specify the path for saving\n",
      "    validation_summary_path = f\"{file_name}_cleaned_validation.xlsx\"\n",
      "    \n",
      "    # Save the DataFrame to Excel\n",
      "    validation_summary_df.to_excel(validation_summary_path, index=False)\n",
      "    print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "else:\n",
      "    print(\"All crab IDs have the correct number of rows (30) in each observation window.\")\n",
      "# CALCULATE NV PRESENCE (assign correct sexes, and maintain column/row order with 30 rows per NV crab (i.e., full obs window)) \n",
      "\n",
      "# Function to calculate NV crabs\n",
      "def calculate_nv_crabs_with_sex(df):\n",
      "    updated_rows = []  # Placeholder for updated rows with NV crabs\n",
      "\n",
      "    # Group by video file, tide category, and observation period\n",
      "    grouped = df.groupby(['video file', 'tide category', 'selected observation period start'])\n",
      "\n",
      "    for (video_file, tide_category, obs_start), group in grouped:\n",
      "        # Get the present population details\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        present_males = group['present males'].iloc[0]\n",
      "        present_females = group['present females'].iloc[0]\n",
      "        \n",
      "        # Get the observed male and female crab counts (excluding NV crabs)\n",
      "        observed_males = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'm'), 'crab ID'].nunique()\n",
      "        observed_females = group.loc[(group['instantaneous behaviour'] != 'NV') & (group['sex'] == 'f'), 'crab ID'].nunique()\n",
      "        \n",
      "        # Calculate the number of NV males and NV females\n",
      "        num_nv_males = present_males - observed_males\n",
      "        num_nv_females = present_females - observed_females\n",
      "        \n",
      "        # Add NV males with 30 rows each\n",
      "        for i in range(1, num_nv_males + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV male\n",
      "                nv_male_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_m{i}',\n",
      "                    'sex': 'm',  # Assign male\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_male_row]))\n",
      "        \n",
      "        # Add NV females with 30 rows each\n",
      "        for i in range(1, num_nv_females + 1):\n",
      "            for minute in range(1, 31):  # Create 30 rows per NV female\n",
      "                nv_female_row = {\n",
      "                    'video file': video_file,\n",
      "                    'crabitat': group['crabitat'].iloc[0],\n",
      "                    'season': group['season'].iloc[0],\n",
      "                    'day type': group['day type'].iloc[0],\n",
      "                    'tide category': tide_category,\n",
      "                    'tide type': group['tide type'].iloc[0],  # Add tide type\n",
      "                    'present population': present_population,\n",
      "                    'present sex ratio': group['present sex ratio'].iloc[0],\n",
      "                    'present males': present_males,\n",
      "                    'present females': present_females,\n",
      "                    'selected observation period start': obs_start,\n",
      "                    'real time': group['real time'].iloc[0],\n",
      "                    'observation minute from start': minute,\n",
      "                    'crab ID': f'NV_f{i}',\n",
      "                    'sex': 'f',  # Assign female\n",
      "                    'instantaneous behaviour': 'NV',\n",
      "                    'human visible?': 'N'  # Mark NV crabs as not visible\n",
      "                }\n",
      "                updated_rows.append(pd.DataFrame([nv_female_row]))\n",
      "\n",
      "        # Add the original group of observed crabs back to the updated rows\n",
      "        updated_rows.append(group)\n",
      "\n",
      "    # Concatenate all the updated rows (including NV crabs) into a single DataFrame\n",
      "    nv_df = pd.concat(updated_rows, ignore_index=True)\n",
      "\n",
      "    # Sort the rows based on the original observation order\n",
      "    nv_df = nv_df.sort_values(by=['video file', 'tide category', 'selected observation period start', 'observation minute from start'])\n",
      "\n",
      "    # Ensure the correct column order\n",
      "    column_order = ['video file', 'crabitat', 'season', 'day type', 'tide category', 'tide type', 'present population',\n",
      "                    'present sex ratio', 'present males', 'present females', 'selected observation period start',\n",
      "                    'real time', 'observation minute from start', 'crab ID', 'sex', 'instantaneous behaviour', 'human visible?']\n",
      "\n",
      "    nv_df = nv_df[column_order]\n",
      "\n",
      "    return nv_df\n",
      "\n",
      "# Apply the NV calculation function\n",
      "df_with_nv = calculate_nv_crabs_with_sex(df_with_tide_categories_and_types)\n",
      "\n",
      "# Remove rows where 'crab ID' is exactly 'NV' - i.e., obs windows where no one showed \n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "# Save the output to a new file\n",
      "output_path_2 = f\"{file_name}_cleaned+NV{file_extension}\"\n",
      "df_with_nv.to_excel(output_path_2, index=False)\n",
      "print(f\"Cleaned dataframe including NVs saved to: {output_path_2}\")\n",
      "# DATA VALIDATION (_cleaned+NV) (30obs/crabID + NV)\n",
      "df_with_nv = df_with_nv[df_with_nv['crab ID'] != 'NV']\n",
      "\n",
      "def validate_data(df):\n",
      "    # Create a list to store validation results\n",
      "    validation_results = []\n",
      "    # Keep track of duplicates\n",
      "    duplicates_list = []\n",
      "\n",
      "    # Group by video file and tide category\n",
      "    grouped = df.groupby(['video file', 'tide category'])\n",
      "\n",
      "    for (video_file, tide_category), group in grouped:\n",
      "        # Calculate expected number of rows\n",
      "        present_population = group['present population'].iloc[0]\n",
      "        expected_rows = present_population * 30\n",
      "        \n",
      "        # Calculate actual rows based on unique combinations\n",
      "        actual_rows = df[(df['video file'] == video_file) & (df['tide category'] == tide_category)].shape[0]\n",
      "\n",
      "        missing_rows = expected_rows - actual_rows\n",
      "\n",
      "        # Append validation result to the list\n",
      "        validation_results.append({\n",
      "            'video file': video_file,\n",
      "            'tide category': tide_category,\n",
      "            'expected rows': expected_rows,\n",
      "            'actual rows': actual_rows,\n",
      "            'missing rows': missing_rows\n",
      "        })\n",
      "\n",
      "        # Check for duplicates based on relevant columns\n",
      "        duplicate_columns = ['selected observation period start', 'observation minute from start', 'crab ID']\n",
      "        duplicates = group[group.duplicated(subset=duplicate_columns, keep=False)]  # Get all duplicate rows\n",
      "\n",
      "        # If duplicates exist, append to duplicates list\n",
      "        if not duplicates.empty:\n",
      "            duplicates_list.append({\n",
      "                'video file': video_file,\n",
      "                'tide category': tide_category,\n",
      "                'duplicates': duplicates.to_dict(orient='records')  # Store duplicate rows\n",
      "            })\n",
      "\n",
      "        # Check for NaN values in critical columns\n",
      "        for column in ['video file', 'tide category', 'present population']:\n",
      "            if df[column].isnull().any():\n",
      "                print(f\"NaN values found in column '{column}'.\")\n",
      "\n",
      "        # Check observation minute range\n",
      "        if not ((df['observation minute from start'] >= 1).all() and (df['observation minute from start'] <= 30).all()):\n",
      "            print(\"Observation minutes out of expected range (1-30).\")\n",
      "\n",
      "    # Create a DataFrame from the results list\n",
      "    validation_results_df = pd.DataFrame(validation_results)\n",
      "\n",
      "    # Filter out results with 0 missing rows\n",
      "    validation_results_df = validation_results_df[validation_results_df['missing rows'] != 0]\n",
      "\n",
      "    # Save duplicates if any\n",
      "    duplicates_df = pd.DataFrame(duplicates_list)\n",
      "\n",
      "    # Display the validation summary\n",
      "    print(validation_results_df)\n",
      "    print(\"Duplicates found:\")\n",
      "    print(duplicates_df)\n",
      "\n",
      "    return validation_results_df, duplicates_df\n",
      "\n",
      "# Use the validation function and save outputs\n",
      "validation_summary, duplicates = validate_data(df)\n",
      "\n",
      "# Save validation summary to Excel\n",
      "validation_summary_path = f\"{file_name}_cleaned+NV_validation.xlsx\"\n",
      "validation_summary.to_excel(validation_summary_path, index=False)\n",
      "print(f\"Validation summary saved to: {validation_summary_path}\")\n",
      "\n",
      "# Save duplicates to CSV if needed\n",
      "if not duplicates.empty:\n",
      "    duplicates_path = f\"{file_name}_cleaned+NV_duplicates.csv\"\n",
      "    duplicates.to_csv(duplicates_path, index=False)\n",
      "    print(f\"Duplicates saved to: {duplicates_path}\")\n",
      "# if I lost anything in editing, here are historical commands run:\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "# if I lost anything in editing, here are historical commands run:\n",
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51818e7-55ae-4c0e-9558-936af21443c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
